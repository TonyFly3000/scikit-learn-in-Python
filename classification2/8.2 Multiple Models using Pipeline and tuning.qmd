---
title: "Multiple models using downsample,pipeline,fast tuning"
subtitle: "with hotel booking imbalanced data"
execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---

Since we have enough rare class data(at least 1K).Let handle imbalanced data with down sample before training.


# load package

```{python}
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import numpy as np
from sklearn import tree
from sklearn.model_selection import train_test_split

from siuba.siu import call
from siuba import _, mutate, filter, group_by, summarize,show_query

import time
from sklearn.experimental import enable_halving_search_cv  # noqa
from sklearn.model_selection import HalvingGridSearchCV

```

# data

## download data


```{python}
import pandas as pd
#url='https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-11/hotels.csv'
#hotels=pd.read_csv(url)

hotels=pd.read_csv('data/hotels.csv')

```

```{python}
hotels.head()

```

## data EDA

Missing Data

```{python}
hotels.isnull().sum()
```

```{python}
#import math
#hotels=hotels>> filter(math.isnan(_.children)==False)
from siuba.siu import call
from siuba import _, mutate, filter, group_by, summarize,show_query
from siuba import *

hotels=hotels.drop('company', axis=1)

hotels >> group_by(_.children)  >> summarize(n = _.shape[0])

```

```{python}
#import math
hotels=hotels>>mutate(children=if_else(_.children > 0, True, False))

# Create a boolean mask and apply it
mask = pd.notna(hotels['children'])
hotels = hotels[mask]

```

## Data Wrangling

```{python}
# Store target variable of training data in a safe place
children_train = hotels .children

# Concatenate training and test sets
data  = hotels
```

## categorical_cols and numerical_cols

```{python}
categorical_cols = [cname for cname in data 
                    if data[cname].nunique() < 10 and data[cname].dtype == "object"]
                    
                    
numerical_cols = numerical_cols = [cname for cname in data.columns 
                    if data[cname].dtype in ['int64', 'float64']]
```

```{python}
print("The total number of categorical columns:", len(categorical_cols))
print("The total number of numerical columns:", len(numerical_cols))
```

```{python}
data >> group_by(_.children)  >> summarize(n = _.shape[0])
```



## split data

80% training / 10% validation/ 10% testing

![](images/1_Nv2NNALuokZEcV6hYEHdGA.webp){width="520"}

```{python}
Y=data['children']
X=data.drop('children', axis=1)

training_size=0.8
validation_size=0.1
testing_size=0.1


X_train, X_val, Y_train, Y_val= train_test_split(X, Y, test_size=validation_size, random_state=1)

X_train, X_test, Y_train, Y_test= train_test_split(X_train, Y_train, test_size=testing_size/training_size, random_state=1) 
```



```{python}    
from imblearn.under_sampling import RandomUnderSampler

ros=RandomUnderSampler(random_state=0)

X_train_resample,Y_train_resample=ros.fit_resample(X_train,Y_train)


```

```{python}
X_train_resample.shape
```

```{python}
Y_train_resample.shape
```

```{python}
len(X_train)/(len(X_train) +len(X_val) +len(X_test) )
```

```{python}
len(X_val)/(len(X_train) +len(X_val) +len(X_test) )
```

```{python}
len(X_test)/(len(X_train) +len(X_val) +len(X_test) )
```


```{python}
Y_train.value_counts()
```

```{python}
Y_train_resample.value_counts()
```
```{python}
Y_test.value_counts()
```

```{python}
Y_val.value_counts()
```

## categorical_cols and numerical_cols


```{python}
categorical_cols = [cname for cname in X_train.columns 
                    if X_train[cname].nunique() < 10 and X_train[cname].dtype == "object"]
                    
                    
numerical_cols = numerical_cols = [cname for cname in X_train.columns 
                    if X_train[cname].dtype in ['int64', 'float64']]
```

```{python}
print("The total number of categorical columns:", len(categorical_cols))
print("The total number of numerical columns:", len(numerical_cols))
```


```{python}
my_cols = categorical_cols + numerical_cols
X_train_resample = X_train_resample[my_cols].copy()
X_val = X_val[my_cols].copy()
X_test= X_test[my_cols].copy()

my_cols
#X_final = df_test[my_cols].copy()
```


## Pipelines for Data Preprocessing

```{python}
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
```


```{python}
numerical_transformer = Pipeline(steps=[
    ('imputer_num', SimpleImputer(strategy='median')), 
    ('scaler', StandardScaler())
])
```




```{python}
from sklearn.preprocessing import OneHotEncoder

categorical_transformer = Pipeline(steps=[
    ('imputer_cat', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])
```


```{python}
from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer(transformers=[
    ('num', numerical_transformer, numerical_cols),
    ('cat', categorical_transformer, categorical_cols)])
```


# model


## define model


### XGB model

```{python}
import xgboost
print(xgboost.__version__)
```

```{python}
from xgboost import XGBClassifier
xgb_model = XGBClassifier()
xgb_model
```

### Random Forest model
```{python}
from sklearn.ensemble import RandomForestClassifier
random_forest_model = RandomForestClassifier()
random_forest_model
```

### Logistic Regression model

```{python}
from sklearn.linear_model import LogisticRegression
LogisticRegression_model = LogisticRegression(solver='liblinear')
LogisticRegression_model
```



## define pipline

```{python}
pipeline_xgb = Pipeline(
  steps=[
         ('preprocessor', preprocessor), 
         ('model', xgb_model)
         ]
)

pipeline_rf = Pipeline(
  steps=[
         ('preprocessor', preprocessor), 
         ('model', random_forest_model)
         ]
)

pipeline_lr = Pipeline(
  steps=[
         ('preprocessor', preprocessor), 
         ('model', LogisticRegression_model)
         ]
)
```

## define GridSearch

```{python}         

parameters_xgb= {
        'model__learning_rate': [0.01, 0.02,0.08,0.1],
        'model__max_depth': [3, 5, 7,8,9,10],
        'model__min_child_weight': [1, 3,5,8],
        'model__subsample': [0.5, 0.7,0.9],
        
       # 'model__colsample__bytree': [0.5, 0.7],
       
        'model__n_estimators' : [100, 200],
        'model__objective': ['reg:squarederror']
    }


Grid_xgb = HalvingGridSearchCV(pipeline_xgb
                ,parameters_xgb 
                ,scoring='accuracy'
                ,max_resources=50
                , cv=10, n_jobs=-1)
                
                
parameters_rf = {'model__max_depth':[20,30,40],
                 'model__n_estimators':[200,250],
                 'model__min_samples_leaf':[1,2,3]
                 }                
                

Grid_rf = HalvingGridSearchCV(pipeline_rf
                ,parameters_rf
                ,scoring='accuracy'
                ,max_resources=50
                , cv=10, n_jobs=-1)
                
                

```

## train model

```{python}
start_time = time.time()


Grids = [Grid_xgb, Grid_rf,pipeline_xgb,pipeline_rf,pipeline_lr]
for Grid in Grids:
    Grid.fit(X_train_resample,Y_train_resample)


end_time = time.time()
duration = end_time - start_time
duration

print("trainning time:",duration)

```

## Preformance

```{python}
grid_dict = {0: 'XGB', 1: 'random forest', 2: 'XGB non tune',3: 'ramdon forest non tune',4:'Logistic regression non tune' }

for i, model in enumerate(Grids):
    print('{} Test Accuracy: {}'.format(grid_dict[i],
    model.score(X_test,Y_test)))
    #print('{} Best Params: {}'.format(grid_dict[i], model.best_params_))
```
```{python}
from sklearn import metrics
for i, model in enumerate(Grids):
    Y_pred_dt = model.predict(X_test)
    print('{} Test auc: {}'.format(grid_dict[i],
    metrics.roc_auc_score(Y_test, Y_pred_dt)))
  
```

```{python}
best_ml=Grid_xgb.best_estimator_
```

```{python}
#Using predict method to test the model
Y_pred_dt = best_ml.predict(X_test) #always gets x and retuns y
Y_pred_dt
```





a)  Accuracy

```{python}
# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives
# Here is another way to find the accuracy score
from sklearn import metrics
accuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  
accuracy
```

b)  Precision

```{python}
# Precision = true positive / true positive + false positive
precision_dt = metrics.precision_score(Y_test,Y_pred_dt)  
precision_dt
```

c)  Recall

```{python}
# Recall = true positive / true positive + false negative
recall_dt = metrics.recall_score(Y_test,Y_pred_dt)  
recall_dt
```

d)  Confusion matrix

```{python}
import seaborn as sns
confusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)
confusion_matrix_dt
```

```{python}
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_estimator(best_ml, X_test, Y_test)
plt.show()
```

e)  AUC - ROC Curve

```{python}
auc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score
auc_dt
```


```{python}
fpr, tpr, thresholds = metrics.roc_curve(Y_test, Y_pred_dt)
roc_auc = metrics.auc(fpr, tpr)

display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,
                                 estimator_name='example estimator')

display.plot()

plt.show()
```

## k-Fold Cross-Validation

```{python}
import numpy as np
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
```

```{python}
kf_dt = KFold(n_splits=5,shuffle=True)  
cv_dt = cross_val_score(pipeline_xgb, X_train, Y_train, cv=kf_dt)
np.mean(cv_dt)
```

## save model
 

```{python}
from joblib import dump, load
dump(Grid_xgb, 'trained_grid_8_2.joblib', compress=True)  
``` 

## load model

```{python}
model_reload = load('trained_grid_8_2.joblib') 
```


```{python}
best_ml=model_reload.best_estimator_
```

## final prediction

```{python}
Y_pred_dt_final =best_ml.predict(X_val) #always gets x and retuns y

Y_pred_dt_final[0:5]
```


```{python}
import collections, numpy
collections.Counter(Y_pred_dt_final)
```



# reference:
