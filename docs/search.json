[
  {
    "objectID": "home/1 index.html",
    "href": "home/1 index.html",
    "title": "About",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\nhttps://tonyfly3000.github.io/scikit-learn-in-Python/\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#download-data",
    "href": "classification/0 titanic data.html#download-data",
    "title": "Titanic Dataset",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/c/titanic/data",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#input-data",
    "href": "classification/0 titanic data.html#input-data",
    "title": "Titanic Dataset",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#data-eda",
    "href": "classification/0 titanic data.html#data-eda",
    "title": "Titanic Dataset",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA\n\n\nCode\ndf_train.describe()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nAge\nSibSp\nParch\nFare\n\n\n\n\ncount\n891.000000\n891.000000\n891.000000\n714.000000\n891.000000\n891.000000\n891.000000\n\n\nmean\n446.000000\n0.383838\n2.308642\n29.699118\n0.523008\n0.381594\n32.204208\n\n\nstd\n257.353842\n0.486592\n0.836071\n14.526497\n1.102743\n0.806057\n49.693429\n\n\nmin\n1.000000\n0.000000\n1.000000\n0.420000\n0.000000\n0.000000\n0.000000\n\n\n25%\n223.500000\n0.000000\n2.000000\n20.125000\n0.000000\n0.000000\n7.910400\n\n\n50%\n446.000000\n0.000000\n3.000000\n28.000000\n0.000000\n0.000000\n14.454200\n\n\n75%\n668.500000\n1.000000\n3.000000\n38.000000\n1.000000\n0.000000\n31.000000\n\n\nmax\n891.000000\n1.000000\n3.000000\n80.000000\n8.000000\n6.000000\n512.329200\n\n\n\n\n\n\n\n\n\n\nCode\ndf_train.describe(include=[object])\n\n\n\n\n\n\n\n\n\n\nName\nSex\nTicket\nCabin\nEmbarked\n\n\n\n\ncount\n891\n891\n891\n204\n889\n\n\nunique\n891\n2\n681\n147\n3\n\n\ntop\nBraund, Mr. Owen Harris\nmale\n347082\nB96 B98\nS\n\n\nfreq\n1\n577\n7\n4\n644\n\n\n\n\n\n\n\n\nMissing Data\n\n\nCode\ndf_train.isnull().sum()\n\n\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\n\n\n\nCode\nimport seaborn as sns\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport sweetviz as sv\nmy_report = sv.analyze(df_train)\n\n\n\n\n\n\n\nCode\nmy_report.show_notebook()",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#feature-vs-target",
    "href": "classification/0 titanic data.html#feature-vs-target",
    "title": "Titanic Dataset",
    "section": "2.4 feature vs target",
    "text": "2.4 feature vs target\n\n\nCode\nmy_report2 = sv.analyze(df_train,target_feat='Survived')\n\n\n\n\n\n\n\nCode\nmy_report2.show_notebook()",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#compare-train-data-and-test-data",
    "href": "classification/0 titanic data.html#compare-train-data-and-test-data",
    "title": "Titanic Dataset",
    "section": "2.5 compare train data and test data",
    "text": "2.5 compare train data and test data\n\n\nCode\ncompare = sv.compare(source=df_train, compare=df_test)\n\n\n\n\n\n\n\nCode\ncompare.show_notebook()",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "classification/0 titanic data.html#data-dictionary",
    "href": "classification/0 titanic data.html#data-dictionary",
    "title": "Titanic Dataset",
    "section": "2.6 data dictionary",
    "text": "2.6 data dictionary\npclass: A proxy for socio-economic status (SES) 1st = Upper 2nd = Middle 3rd = Lower\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\nsibsp: The dataset defines family relations in this way…\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fiancés were ignored)\nparch: The dataset defines family relations in this way…\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson Some children travelled only with a nanny, therefore parch=0 for them.",
    "crumbs": [
      "Classification",
      "Titanic Dataset"
    ]
  },
  {
    "objectID": "data/1 Pandas.html",
    "href": "data/1 Pandas.html",
    "title": "Data manipulation with Pandas",
    "section": "",
    "text": "Code\nimport sys\nprint(sys.version)\n\n\n3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\nCode\nimport pandas as pd\nprint('pandas version', pd.__version__)\n\n\npandas version 2.2.1",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#reading-from-parquet",
    "href": "data/1 Pandas.html#reading-from-parquet",
    "title": "Data manipulation with Pandas",
    "section": "0.1 Reading from parquet",
    "text": "0.1 Reading from parquet\n\n\nCode\ndf = pd.read_parquet(\"data/Combined_Flights_2022.parquet\")",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-first-3",
    "href": "data/1 Pandas.html#get-first-3",
    "title": "Data manipulation with Pandas",
    "section": "0.2 get first 3",
    "text": "0.2 get first 3\n\n\nCode\ndf.head(3)\n\n\n\n\n\n\n\n\n\n\nFlightDate\nAirline\nOrigin\nDest\nCancelled\nDiverted\nCRSDepTime\nDepTime\nDepDelayMinutes\nDepDelay\n...\nWheelsOff\nWheelsOn\nTaxiIn\nCRSArrTime\nArrDelay\nArrDel15\nArrivalDelayGroups\nArrTimeBlk\nDistanceGroup\nDivAirportLandings\n\n\n\n\n0\n2022-04-04\nCommutair Aka Champlain Enterprises, Inc.\nGJT\nDEN\nFalse\nFalse\n1133\n1123.0\n0.0\n-10.0\n...\n1140.0\n1220.0\n8.0\n1245\n-17.0\n0.0\n-2.0\n1200-1259\n1\n0\n\n\n1\n2022-04-04\nCommutair Aka Champlain Enterprises, Inc.\nHRL\nIAH\nFalse\nFalse\n732\n728.0\n0.0\n-4.0\n...\n744.0\n839.0\n9.0\n849\n-1.0\n0.0\n-1.0\n0800-0859\n2\n0\n\n\n2\n2022-04-04\nCommutair Aka Champlain Enterprises, Inc.\nDRO\nDEN\nFalse\nFalse\n1529\n1514.0\n0.0\n-15.0\n...\n1535.0\n1622.0\n14.0\n1639\n-3.0\n0.0\n-1.0\n1600-1659\n2\n0\n\n\n\n\n3 rows × 61 columns",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-last-3",
    "href": "data/1 Pandas.html#get-last-3",
    "title": "Data manipulation with Pandas",
    "section": "0.3 get last 3",
    "text": "0.3 get last 3\n\n\nCode\ndf.tail(3)\n\n\n\n\n\n\n\n\n\n\nFlightDate\nAirline\nOrigin\nDest\nCancelled\nDiverted\nCRSDepTime\nDepTime\nDepDelayMinutes\nDepDelay\n...\nWheelsOff\nWheelsOn\nTaxiIn\nCRSArrTime\nArrDelay\nArrDel15\nArrivalDelayGroups\nArrTimeBlk\nDistanceGroup\nDivAirportLandings\n\n\n\n\n590539\n2022-03-08\nRepublic Airlines\nALB\nORD\nFalse\nFalse\n1700\n2318.0\n378.0\n378.0\n...\n2337.0\n52.0\n7.0\n1838\n381.0\n1.0\n12.0\n1800-1859\n3\n0\n\n\n590540\n2022-03-25\nRepublic Airlines\nEWR\nPIT\nFalse\nTrue\n2129\n2322.0\n113.0\n113.0\n...\n2347.0\n933.0\n6.0\n2255\nNaN\nNaN\nNaN\n2200-2259\n2\n1\n\n\n590541\n2022-03-07\nRepublic Airlines\nEWR\nRDU\nFalse\nTrue\n1154\n1148.0\n0.0\n-6.0\n...\n1201.0\n1552.0\n4.0\n1333\nNaN\nNaN\nNaN\n1300-1359\n2\n1\n\n\n\n\n3 rows × 61 columns",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-ramdon-5",
    "href": "data/1 Pandas.html#get-ramdon-5",
    "title": "Data manipulation with Pandas",
    "section": "0.4 get ramdon 5",
    "text": "0.4 get ramdon 5\n\n\nCode\ndf.sample(5, random_state=42)\n\n\n\n\n\n\n\n\n\n\nFlightDate\nAirline\nOrigin\nDest\nCancelled\nDiverted\nCRSDepTime\nDepTime\nDepDelayMinutes\nDepDelay\n...\nWheelsOff\nWheelsOn\nTaxiIn\nCRSArrTime\nArrDelay\nArrDel15\nArrivalDelayGroups\nArrTimeBlk\nDistanceGroup\nDivAirportLandings\n\n\n\n\n324021\n2022-03-19\nSkyWest Airlines Inc.\nASE\nDEN\nFalse\nFalse\n1831\n1826.0\n0.0\n-5.0\n...\n1845.0\n1916.0\n7.0\n1933\n-10.0\n0.0\n-1.0\n1900-1959\n1\n0\n\n\n34739\n2022-02-16\nSkyWest Airlines Inc.\nTYS\nDEN\nFalse\nFalse\n1605\n1605.0\n0.0\n0.0\n...\n1614.0\n1728.0\n44.0\n1737\n35.0\n1.0\n2.0\n1700-1759\n5\n0\n\n\n304494\n2022-01-18\nAmerican Airlines Inc.\nLAX\nOGG\nFalse\nFalse\n1719\n1714.0\n0.0\n-5.0\n...\n1728.0\n2042.0\n10.0\n2049\n3.0\n0.0\n0.0\n2000-2059\n10\n0\n\n\n205451\n2022-01-23\nSouthwest Airlines Co.\nLAS\nBWI\nFalse\nFalse\n1515\n1533.0\n18.0\n18.0\n...\n1548.0\n2259.0\n3.0\n2235\n27.0\n1.0\n1.0\n2200-2259\n9\n0\n\n\n173176\n2022-07-01\nDelta Air Lines Inc.\nDTW\nRDU\nFalse\nFalse\n715\n709.0\n0.0\n-6.0\n...\n721.0\n834.0\n3.0\n853\n-16.0\n0.0\n-2.0\n0800-0859\n3\n0\n\n\n\n\n5 rows × 61 columns",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-columns-names",
    "href": "data/1 Pandas.html#get-columns-names",
    "title": "Data manipulation with Pandas",
    "section": "0.5 get columns names",
    "text": "0.5 get columns names\n\n\nCode\ndf.columns\n\n\nIndex(['FlightDate', 'Airline', 'Origin', 'Dest', 'Cancelled', 'Diverted',\n       'CRSDepTime', 'DepTime', 'DepDelayMinutes', 'DepDelay', 'ArrTime',\n       'ArrDelayMinutes', 'AirTime', 'CRSElapsedTime', 'ActualElapsedTime',\n       'Distance', 'Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek',\n       'Marketing_Airline_Network', 'Operated_or_Branded_Code_Share_Partners',\n       'DOT_ID_Marketing_Airline', 'IATA_Code_Marketing_Airline',\n       'Flight_Number_Marketing_Airline', 'Operating_Airline',\n       'DOT_ID_Operating_Airline', 'IATA_Code_Operating_Airline',\n       'Tail_Number', 'Flight_Number_Operating_Airline', 'OriginAirportID',\n       'OriginAirportSeqID', 'OriginCityMarketID', 'OriginCityName',\n       'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac',\n       'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'DestCityName',\n       'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'DepDel15',\n       'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff',\n       'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrDelay', 'ArrDel15',\n       'ArrivalDelayGroups', 'ArrTimeBlk', 'DistanceGroup',\n       'DivAirportLandings'],\n      dtype='object')",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-row-index",
    "href": "data/1 Pandas.html#get-row-index",
    "title": "Data manipulation with Pandas",
    "section": "0.6 get row index",
    "text": "0.6 get row index\n\n\nCode\ndf.index\n\n\nIndex([     0,      1,      2,      3,      4,      5,      6,      7,      8,\n            9,\n       ...\n       590532, 590533, 590534, 590535, 590536, 590537, 590538, 590539, 590540,\n       590541],\n      dtype='int64', length=4078318)",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-long-info",
    "href": "data/1 Pandas.html#get-long-info",
    "title": "Data manipulation with Pandas",
    "section": "0.7 get long info",
    "text": "0.7 get long info\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4078318 entries, 0 to 590541\nData columns (total 61 columns):\n #   Column                                   Dtype         \n---  ------                                   -----         \n 0   FlightDate                               datetime64[us]\n 1   Airline                                  object        \n 2   Origin                                   object        \n 3   Dest                                     object        \n 4   Cancelled                                bool          \n 5   Diverted                                 bool          \n 6   CRSDepTime                               int64         \n 7   DepTime                                  float64       \n 8   DepDelayMinutes                          float64       \n 9   DepDelay                                 float64       \n 10  ArrTime                                  float64       \n 11  ArrDelayMinutes                          float64       \n 12  AirTime                                  float64       \n 13  CRSElapsedTime                           float64       \n 14  ActualElapsedTime                        float64       \n 15  Distance                                 float64       \n 16  Year                                     int64         \n 17  Quarter                                  int64         \n 18  Month                                    int64         \n 19  DayofMonth                               int64         \n 20  DayOfWeek                                int64         \n 21  Marketing_Airline_Network                object        \n 22  Operated_or_Branded_Code_Share_Partners  object        \n 23  DOT_ID_Marketing_Airline                 int64         \n 24  IATA_Code_Marketing_Airline              object        \n 25  Flight_Number_Marketing_Airline          int64         \n 26  Operating_Airline                        object        \n 27  DOT_ID_Operating_Airline                 int64         \n 28  IATA_Code_Operating_Airline              object        \n 29  Tail_Number                              object        \n 30  Flight_Number_Operating_Airline          int64         \n 31  OriginAirportID                          int64         \n 32  OriginAirportSeqID                       int64         \n 33  OriginCityMarketID                       int64         \n 34  OriginCityName                           object        \n 35  OriginState                              object        \n 36  OriginStateFips                          int64         \n 37  OriginStateName                          object        \n 38  OriginWac                                int64         \n 39  DestAirportID                            int64         \n 40  DestAirportSeqID                         int64         \n 41  DestCityMarketID                         int64         \n 42  DestCityName                             object        \n 43  DestState                                object        \n 44  DestStateFips                            int64         \n 45  DestStateName                            object        \n 46  DestWac                                  int64         \n 47  DepDel15                                 float64       \n 48  DepartureDelayGroups                     float64       \n 49  DepTimeBlk                               object        \n 50  TaxiOut                                  float64       \n 51  WheelsOff                                float64       \n 52  WheelsOn                                 float64       \n 53  TaxiIn                                   float64       \n 54  CRSArrTime                               int64         \n 55  ArrDelay                                 float64       \n 56  ArrDel15                                 float64       \n 57  ArrivalDelayGroups                       float64       \n 58  ArrTimeBlk                               object        \n 59  DistanceGroup                            int64         \n 60  DivAirportLandings                       int64         \ndtypes: bool(2), datetime64[us](1), float64(18), int64(23), object(17)\nmemory usage: 1.8+ GB",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#get-short-info",
    "href": "data/1 Pandas.html#get-short-info",
    "title": "Data manipulation with Pandas",
    "section": "0.8 get short info",
    "text": "0.8 get short info\n\n\nCode\ndf.info(verbose=False)\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 4078318 entries, 0 to 590541\nColumns: 61 entries, FlightDate to DivAirportLandings\ndtypes: bool(2), datetime64[us](1), float64(18), int64(23), object(17)\nmemory usage: 1.8+ GB",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#summary-of-numeric-column",
    "href": "data/1 Pandas.html#summary-of-numeric-column",
    "title": "Data manipulation with Pandas",
    "section": "0.9 summary of numeric column",
    "text": "0.9 summary of numeric column\n\n\nCode\ndf.describe()\n\n\n\n\n\n\n\n\n\n\nFlightDate\nCRSDepTime\nDepTime\nDepDelayMinutes\nDepDelay\nArrTime\nArrDelayMinutes\nAirTime\nCRSElapsedTime\nActualElapsedTime\n...\nTaxiOut\nWheelsOff\nWheelsOn\nTaxiIn\nCRSArrTime\nArrDelay\nArrDel15\nArrivalDelayGroups\nDistanceGroup\nDivAirportLandings\n\n\n\n\ncount\n4078318\n4.078318e+06\n3.957885e+06\n3.957823e+06\n3.957823e+06\n3.954079e+06\n3.944916e+06\n3.944916e+06\n4.078318e+06\n3.944916e+06\n...\n3.955652e+06\n3.955652e+06\n3.954076e+06\n3.954076e+06\n4.078318e+06\n3.944916e+06\n3.944916e+06\n3.944916e+06\n4.078318e+06\n4.078318e+06\n\n\nmean\n2022-04-18 12:10:43.903101\n1.329587e+03\n1.334374e+03\n1.601494e+01\n1.309049e+01\n1.457886e+03\n1.578307e+01\n1.110075e+02\n1.413211e+02\n1.358624e+02\n...\n1.697375e+01\n1.356576e+03\n1.455073e+03\n7.894387e+00\n1.486058e+03\n7.528486e+00\n2.164715e-01\n-6.256103e-02\n3.663516e+00\n3.685098e-03\n\n\nmin\n2022-01-01 00:00:00\n1.000000e+00\n1.000000e+00\n0.000000e+00\n-7.800000e+01\n1.000000e+00\n0.000000e+00\n8.000000e+00\n-4.800000e+01\n1.400000e+01\n...\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n1.000000e+00\n-1.000000e+02\n0.000000e+00\n-2.000000e+00\n1.000000e+00\n0.000000e+00\n\n\n25%\n2022-02-25 00:00:00\n9.140000e+02\n9.170000e+02\n0.000000e+00\n-5.000000e+00\n1.046000e+03\n0.000000e+00\n6.000000e+01\n8.900000e+01\n8.300000e+01\n...\n1.100000e+01\n9.320000e+02\n1.044000e+03\n4.000000e+00\n1.103000e+03\n-1.400000e+01\n0.000000e+00\n-1.000000e+00\n2.000000e+00\n0.000000e+00\n\n\n50%\n2022-04-19 00:00:00\n1.320000e+03\n1.325000e+03\n0.000000e+00\n-2.000000e+00\n1.500000e+03\n0.000000e+00\n9.400000e+01\n1.240000e+02\n1.190000e+02\n...\n1.500000e+01\n1.338000e+03\n1.456000e+03\n6.000000e+00\n1.513000e+03\n-5.000000e+00\n0.000000e+00\n-1.000000e+00\n3.000000e+00\n0.000000e+00\n\n\n75%\n2022-06-11 00:00:00\n1.735000e+03\n1.744000e+03\n1.100000e+01\n1.100000e+01\n1.914000e+03\n1.000000e+01\n1.410000e+02\n1.710000e+02\n1.670000e+02\n...\n1.900000e+01\n1.758000e+03\n1.909000e+03\n9.000000e+00\n1.920000e+03\n1.000000e+01\n0.000000e+00\n0.000000e+00\n5.000000e+00\n0.000000e+00\n\n\nmax\n2022-07-31 00:00:00\n2.359000e+03\n2.400000e+03\n7.223000e+03\n7.223000e+03\n2.400000e+03\n7.232000e+03\n7.270000e+02\n6.900000e+02\n7.640000e+02\n...\n2.210000e+02\n2.400000e+03\n2.400000e+03\n2.900000e+02\n2.359000e+03\n7.232000e+03\n1.000000e+00\n1.200000e+01\n1.100000e+01\n9.000000e+00\n\n\nstd\nNaN\n4.904801e+02\n5.056219e+02\n5.231498e+01\n5.332016e+01\n5.431841e+02\n5.198424e+01\n6.996246e+01\n7.179635e+01\n7.185501e+01\n...\n9.495407e+00\n5.075580e+02\n5.378428e+02\n6.663118e+00\n5.185078e+02\n5.524625e+01\n4.118393e-01\n2.487442e+00\n2.320848e+00\n1.141331e-01\n\n\n\n\n8 rows × 42 columns",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "data/1 Pandas.html#summary-of-categorical-column",
    "href": "data/1 Pandas.html#summary-of-categorical-column",
    "title": "Data manipulation with Pandas",
    "section": "0.10 summary of categorical column",
    "text": "0.10 summary of categorical column\n\n\nCode\ndf[[\"Airline\"]].describe()\n\n\n\n\n\n\n\n\n\n\nAirline\n\n\n\n\ncount\n4078318\n\n\nunique\n21\n\n\ntop\nSouthwest Airlines Co.\n\n\nfreq\n731925",
    "crumbs": [
      "Data",
      "Data manipulation with Pandas"
    ]
  },
  {
    "objectID": "model type/2 random forest.html",
    "href": "model type/2 random forest.html",
    "title": "Random forest",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nThe size & inference speed of the random forest can sometimes be an issue\nRandom forests cannot learn and reuse internal representations\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8",
    "crumbs": [
      "model type",
      "Random forest"
    ]
  },
  {
    "objectID": "model type/3 gradient boosted trees.html",
    "href": "model type/3 gradient boosted trees.html",
    "title": "Gradient boosted trees",
    "section": "",
    "text": "1 Pros\n\nNative support for numerical and categorical features, and no necessary need for feature pre-processing.\nGBT are fast and light-weight and with great performance.\n\n\n\n2 Cons\n\nGBT can overfit.\nDecision tree trained sequentially -&gt; slower training.\nGBT cannot learn & reuse internal representations.Poor performance on image and long text.\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=w5gB8zyLx-8",
    "crumbs": [
      "model type",
      "Gradient boosted trees"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html",
    "href": "regression/2 Decision Tree on house price data copy.html",
    "title": "Decision tree",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import explained_variance_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#input-data",
    "href": "regression/2 Decision Tree on house price data copy.html#input-data",
    "title": "Decision tree",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nId = df_train['Id']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\n\n\nCode\n#df_train.info()\n\n\n\n\nCode\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['SalePrice'], axis=1), df_test])",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#data-eda",
    "href": "regression/2 Decision Tree on house price data copy.html#data-eda",
    "title": "Decision tree",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\nin step 1",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#data-wrangling",
    "href": "regression/2 Decision Tree on house price data copy.html#data-wrangling",
    "title": "Decision tree",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#split-data",
    "href": "regression/2 Decision Tree on house price data copy.html#split-data",
    "title": "Decision tree",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY = df_train.SalePrice\nX = df_train.drop(['SalePrice'], axis=1)\n\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nprint(X_train.shape)\nprint(X_test.shape)\n\n\n(1168, 80)\n(292, 80)\n\n\n\n\nCode\nprint(Y_train.shape)\nprint(Y_test.shape)\n\n\n(1168,)\n(292,)\n\n\n\n\nCode\ncategorical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].nunique() &lt; 10 and X_train[cname].dtype == \"object\"]\n                    \n                    \nnumerical_cols = numerical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].dtype in ['int64', 'float64']]\n\n\n\n\nCode\nprint(\"The total number of categorical columns:\", len(categorical_cols))\nprint(\"The total number of numerical columns:\", len(numerical_cols))\n\n\nThe total number of categorical columns: 40\nThe total number of numerical columns: 37\n\n\n\n\nCode\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_test= X_test[my_cols].copy()\n\n\nX_final = df_test[my_cols].copy()",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#pipelines-for-data-preprocessing",
    "href": "regression/2 Decision Tree on house price data copy.html#pipelines-for-data-preprocessing",
    "title": "Decision tree",
    "section": "2.5 Pipelines for Data Preprocessing",
    "text": "2.5 Pipelines for Data Preprocessing\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nnumerical_transformer = Pipeline(steps=[\n    ('imputer_num', SimpleImputer(strategy='median')), \n    ('scaler', StandardScaler())\n])\n\n\n\n\nCode\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer_cat', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)])",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#define-model",
    "href": "regression/2 Decision Tree on house price data copy.html#define-model",
    "title": "Decision tree",
    "section": "3.1 define model",
    "text": "3.1 define model\n\n\nCode\nml_model = DecisionTreeRegressor(random_state=0)\nml_model\n\n\nDecisionTreeRegressor(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeRegressor?Documentation for DecisionTreeRegressoriNot fittedDecisionTreeRegressor(random_state=0)",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#define-pipline",
    "href": "regression/2 Decision Tree on house price data copy.html#define-pipline",
    "title": "Decision tree",
    "section": "3.2 define pipline",
    "text": "3.2 define pipline\n\n\nCode\npipeline = Pipeline(\n  steps=[\n         ('preprocessor', preprocessor), \n         ('model_dt', ml_model)\n         ]\n)",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#train-model",
    "href": "regression/2 Decision Tree on house price data copy.html#train-model",
    "title": "Decision tree",
    "section": "3.3 train model",
    "text": "3.3 train model\n\n\nCode\npipeline.fit(X_train, Y_train)\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                                                   'LotConfig', 'LandSlope',\n                                                   'Condition1', 'Condition2',\n                                                   'BldgType', 'HouseStyle',\n                                                   'RoofStyle', 'RoofMatl',\n                                                   'MasVnrType', 'ExterQual',\n                                                   'ExterCond', 'Foundation',\n                                                   'BsmtQual', 'BsmtCond',\n                                                   'BsmtExposure',\n                                                   'BsmtFinType1',\n                                                   'BsmtFinType2', 'Heating',\n                                                   'HeatingQC', 'CentralAir',\n                                                   'Electrical', 'KitchenQual',\n                                                   'Functional', 'FireplaceQu', ...])])),\n                ('model_dt', DecisionTreeRegressor(random_state=0))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                                                   'LotConfig', 'LandSlope',\n                                                   'Condition1', 'Condition2',\n                                                   'BldgType', 'HouseStyle',\n                                                   'RoofStyle', 'RoofMatl',\n                                                   'MasVnrType', 'ExterQual',\n                                                   'ExterCond', 'Foundation',\n                                                   'BsmtQual', 'BsmtCond',\n                                                   'BsmtExposure',\n                                                   'BsmtFinType1',\n                                                   'BsmtFinType2', 'Heating',\n                                                   'HeatingQC', 'CentralAir',\n                                                   'Electrical', 'KitchenQual',\n                                                   'Functional', 'FireplaceQu', ...])])),\n                ('model_dt', DecisionTreeRegressor(random_state=0))])  preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer_num',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 ['Id', 'MSSubClass', 'LotFrontage', 'LotArea',\n                                  'OverallQual', 'OverallCond', 'YearBuilt',\n                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n                                  'GrLivArea', 'Bsm...\n                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n                                  'LandContour', 'Utilities', 'LotConfig',\n                                  'LandSlope', 'Condition1', 'Condition2',\n                                  'BldgType', 'HouseStyle', 'RoofStyle',\n                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n                                  'ExterCond', 'Foundation', 'BsmtQual',\n                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n                                  'CentralAir', 'Electrical', 'KitchenQual',\n                                  'Functional', 'FireplaceQu', ...])]) num['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median')  StandardScaler?Documentation for StandardScalerStandardScaler() cat['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent')  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore')  DecisionTreeRegressor?Documentation for DecisionTreeRegressorDecisionTreeRegressor(random_state=0) \n\n\n\n\nCode\nfitted_model=pipeline.steps[1][1]\n\n\n\n\nCode\nvar=pipeline[:-1].get_feature_names_out()\nvar\n\n\narray(['num__Id', 'num__MSSubClass', 'num__LotFrontage', 'num__LotArea',\n       'num__OverallQual', 'num__OverallCond', 'num__YearBuilt',\n       'num__YearRemodAdd', 'num__MasVnrArea', 'num__BsmtFinSF1',\n       'num__BsmtFinSF2', 'num__BsmtUnfSF', 'num__TotalBsmtSF',\n       'num__1stFlrSF', 'num__2ndFlrSF', 'num__LowQualFinSF',\n       'num__GrLivArea', 'num__BsmtFullBath', 'num__BsmtHalfBath',\n       'num__FullBath', 'num__HalfBath', 'num__BedroomAbvGr',\n       'num__KitchenAbvGr', 'num__TotRmsAbvGrd', 'num__Fireplaces',\n       'num__GarageYrBlt', 'num__GarageCars', 'num__GarageArea',\n       'num__WoodDeckSF', 'num__OpenPorchSF', 'num__EnclosedPorch',\n       'num__3SsnPorch', 'num__ScreenPorch', 'num__PoolArea',\n       'num__MiscVal', 'num__MoSold', 'num__YrSold',\n       'cat__MSZoning_C (all)', 'cat__MSZoning_FV', 'cat__MSZoning_RH',\n       'cat__MSZoning_RL', 'cat__MSZoning_RM', 'cat__Street_Grvl',\n       'cat__Street_Pave', 'cat__Alley_Grvl', 'cat__Alley_Pave',\n       'cat__LotShape_IR1', 'cat__LotShape_IR2', 'cat__LotShape_IR3',\n       'cat__LotShape_Reg', 'cat__LandContour_Bnk',\n       'cat__LandContour_HLS', 'cat__LandContour_Low',\n       'cat__LandContour_Lvl', 'cat__Utilities_AllPub',\n       'cat__Utilities_NoSeWa', 'cat__LotConfig_Corner',\n       'cat__LotConfig_CulDSac', 'cat__LotConfig_FR2',\n       'cat__LotConfig_FR3', 'cat__LotConfig_Inside',\n       'cat__LandSlope_Gtl', 'cat__LandSlope_Mod', 'cat__LandSlope_Sev',\n       'cat__Condition1_Artery', 'cat__Condition1_Feedr',\n       'cat__Condition1_Norm', 'cat__Condition1_PosA',\n       'cat__Condition1_PosN', 'cat__Condition1_RRAe',\n       'cat__Condition1_RRAn', 'cat__Condition1_RRNe',\n       'cat__Condition1_RRNn', 'cat__Condition2_Artery',\n       'cat__Condition2_Feedr', 'cat__Condition2_Norm',\n       'cat__Condition2_PosA', 'cat__Condition2_PosN',\n       'cat__Condition2_RRAe', 'cat__Condition2_RRAn',\n       'cat__Condition2_RRNn', 'cat__BldgType_1Fam',\n       'cat__BldgType_2fmCon', 'cat__BldgType_Duplex',\n       'cat__BldgType_Twnhs', 'cat__BldgType_TwnhsE',\n       'cat__HouseStyle_1.5Fin', 'cat__HouseStyle_1.5Unf',\n       'cat__HouseStyle_1Story', 'cat__HouseStyle_2.5Fin',\n       'cat__HouseStyle_2.5Unf', 'cat__HouseStyle_2Story',\n       'cat__HouseStyle_SFoyer', 'cat__HouseStyle_SLvl',\n       'cat__RoofStyle_Flat', 'cat__RoofStyle_Gable',\n       'cat__RoofStyle_Gambrel', 'cat__RoofStyle_Hip',\n       'cat__RoofStyle_Mansard', 'cat__RoofStyle_Shed',\n       'cat__RoofMatl_ClyTile', 'cat__RoofMatl_CompShg',\n       'cat__RoofMatl_Membran', 'cat__RoofMatl_Tar&Grv',\n       'cat__RoofMatl_WdShake', 'cat__RoofMatl_WdShngl',\n       'cat__MasVnrType_BrkCmn', 'cat__MasVnrType_BrkFace',\n       'cat__MasVnrType_Stone', 'cat__ExterQual_Ex', 'cat__ExterQual_Fa',\n       'cat__ExterQual_Gd', 'cat__ExterQual_TA', 'cat__ExterCond_Ex',\n       'cat__ExterCond_Fa', 'cat__ExterCond_Gd', 'cat__ExterCond_Po',\n       'cat__ExterCond_TA', 'cat__Foundation_BrkTil',\n       'cat__Foundation_CBlock', 'cat__Foundation_PConc',\n       'cat__Foundation_Slab', 'cat__Foundation_Stone',\n       'cat__Foundation_Wood', 'cat__BsmtQual_Ex', 'cat__BsmtQual_Fa',\n       'cat__BsmtQual_Gd', 'cat__BsmtQual_TA', 'cat__BsmtCond_Fa',\n       'cat__BsmtCond_Gd', 'cat__BsmtCond_Po', 'cat__BsmtCond_TA',\n       'cat__BsmtExposure_Av', 'cat__BsmtExposure_Gd',\n       'cat__BsmtExposure_Mn', 'cat__BsmtExposure_No',\n       'cat__BsmtFinType1_ALQ', 'cat__BsmtFinType1_BLQ',\n       'cat__BsmtFinType1_GLQ', 'cat__BsmtFinType1_LwQ',\n       'cat__BsmtFinType1_Rec', 'cat__BsmtFinType1_Unf',\n       'cat__BsmtFinType2_ALQ', 'cat__BsmtFinType2_BLQ',\n       'cat__BsmtFinType2_GLQ', 'cat__BsmtFinType2_LwQ',\n       'cat__BsmtFinType2_Rec', 'cat__BsmtFinType2_Unf',\n       'cat__Heating_Floor', 'cat__Heating_GasA', 'cat__Heating_GasW',\n       'cat__Heating_Grav', 'cat__Heating_OthW', 'cat__Heating_Wall',\n       'cat__HeatingQC_Ex', 'cat__HeatingQC_Fa', 'cat__HeatingQC_Gd',\n       'cat__HeatingQC_Po', 'cat__HeatingQC_TA', 'cat__CentralAir_N',\n       'cat__CentralAir_Y', 'cat__Electrical_FuseA',\n       'cat__Electrical_FuseF', 'cat__Electrical_FuseP',\n       'cat__Electrical_Mix', 'cat__Electrical_SBrkr',\n       'cat__KitchenQual_Ex', 'cat__KitchenQual_Fa',\n       'cat__KitchenQual_Gd', 'cat__KitchenQual_TA',\n       'cat__Functional_Maj1', 'cat__Functional_Maj2',\n       'cat__Functional_Min1', 'cat__Functional_Min2',\n       'cat__Functional_Mod', 'cat__Functional_Sev',\n       'cat__Functional_Typ', 'cat__FireplaceQu_Ex',\n       'cat__FireplaceQu_Fa', 'cat__FireplaceQu_Gd',\n       'cat__FireplaceQu_Po', 'cat__FireplaceQu_TA',\n       'cat__GarageType_2Types', 'cat__GarageType_Attchd',\n       'cat__GarageType_Basment', 'cat__GarageType_BuiltIn',\n       'cat__GarageType_CarPort', 'cat__GarageType_Detchd',\n       'cat__GarageFinish_Fin', 'cat__GarageFinish_RFn',\n       'cat__GarageFinish_Unf', 'cat__GarageQual_Ex',\n       'cat__GarageQual_Fa', 'cat__GarageQual_Gd', 'cat__GarageQual_Po',\n       'cat__GarageQual_TA', 'cat__GarageCond_Ex', 'cat__GarageCond_Fa',\n       'cat__GarageCond_Gd', 'cat__GarageCond_Po', 'cat__GarageCond_TA',\n       'cat__PavedDrive_N', 'cat__PavedDrive_P', 'cat__PavedDrive_Y',\n       'cat__PoolQC_Ex', 'cat__PoolQC_Fa', 'cat__PoolQC_Gd',\n       'cat__Fence_GdPrv', 'cat__Fence_GdWo', 'cat__Fence_MnPrv',\n       'cat__Fence_MnWw', 'cat__MiscFeature_Gar2',\n       'cat__MiscFeature_Othr', 'cat__MiscFeature_Shed',\n       'cat__MiscFeature_TenC', 'cat__SaleType_COD', 'cat__SaleType_CWD',\n       'cat__SaleType_Con', 'cat__SaleType_ConLD', 'cat__SaleType_ConLI',\n       'cat__SaleType_ConLw', 'cat__SaleType_New', 'cat__SaleType_Oth',\n       'cat__SaleType_WD', 'cat__SaleCondition_Abnorml',\n       'cat__SaleCondition_AdjLand', 'cat__SaleCondition_Alloca',\n       'cat__SaleCondition_Family', 'cat__SaleCondition_Normal',\n       'cat__SaleCondition_Partial'], dtype=object)\n\n\nvariable importance\n\n\nCode\nimportances = fitted_model.feature_importances_\nvi=pd.DataFrame({\"variable\":var,\"importances\":importances})\nvi=vi.sort_values('importances',ascending=False)\nvi\n\n\n\n\n\n\n\n\n\n\nvariable\nimportances\n\n\n\n\n4\nnum__OverallQual\n0.598885\n\n\n16\nnum__GrLivArea\n0.099269\n\n\n12\nnum__TotalBsmtSF\n0.091165\n\n\n9\nnum__BsmtFinSF1\n0.036604\n\n\n14\nnum__2ndFlrSF\n0.031550\n\n\n...\n...\n...\n\n\n71\ncat__Condition1_RRNe\n0.000000\n\n\n72\ncat__Condition1_RRNn\n0.000000\n\n\n73\ncat__Condition2_Artery\n0.000000\n\n\n74\ncat__Condition2_Feedr\n0.000000\n\n\n229\ncat__SaleCondition_Partial\n0.000000\n\n\n\n\n230 rows × 2 columns",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#preformance",
    "href": "regression/2 Decision Tree on house price data copy.html#preformance",
    "title": "Decision tree",
    "section": "3.4 Preformance",
    "text": "3.4 Preformance\n\n\nCode\nY_pred_dt =pipeline.predict(X_test) #always gets x and retuns y\n\n\nR 2\n\n\nCode\nfrom sklearn.metrics import r2_score\nr2_score(Y_test, Y_pred_dt)\n\n\n0.7521719039048484\n\n\nMAE\n\n\nCode\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(Y_test, Y_pred_dt)\n\n\n28054.075342465752\n\n\nRMSE\n\n\nCode\nfrom  math import sqrt\nfrom sklearn.metrics import mean_squared_error\nmse=mean_squared_error(Y_test, Y_pred_dt)\nrmse=sqrt(mse)\nrmse\n\n\n40073.3846729202",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/2 Decision Tree on house price data copy.html#k-fold-cross-validation",
    "href": "regression/2 Decision Tree on house price data copy.html#k-fold-cross-validation",
    "title": "Decision tree",
    "section": "3.5 k-Fold Cross-Validation",
    "text": "3.5 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \n\n\n\n\nCode\ncv_dt = cross_val_score(pipeline, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.6730642510816017\n\n\n\n\nCode\ncv_dt = cross_val_score(pipeline, X_train, Y_train, cv=kf_dt,scoring = 'neg_mean_squared_error')\nnp.mean(np.sqrt(np.abs(cv_dt)))\n\n\n45761.96438168637",
    "crumbs": [
      "Regression",
      "Decision tree"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html",
    "href": "regression/5 XGboost on house price data.html",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "",
    "text": "with pipeline and tunning",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#input-data",
    "href": "regression/5 XGboost on house price data.html#input-data",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nId = df_train['Id']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\n\n\nCode\n#df_train.info()\n\n\n\n\nCode\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['SalePrice'], axis=1), df_test])",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#data-eda",
    "href": "regression/5 XGboost on house price data.html#data-eda",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\nin step 1",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#data-wrangling",
    "href": "regression/5 XGboost on house price data.html#data-wrangling",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#split-data",
    "href": "regression/5 XGboost on house price data.html#split-data",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY = df_train.SalePrice\nX = df_train.drop(['SalePrice'], axis=1)\n\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nprint(X_train.shape)\nprint(X_test.shape)\n\n\n(1168, 80)\n(292, 80)\n\n\n\n\nCode\nprint(Y_train.shape)\nprint(Y_test.shape)\n\n\n(1168,)\n(292,)\n\n\n\n\nCode\ncategorical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].nunique() &lt; 10 and X_train[cname].dtype == \"object\"]\n                    \n                    \nnumerical_cols = numerical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].dtype in ['int64', 'float64']]\n\n\n\n\nCode\nprint(\"The total number of categorical columns:\", len(categorical_cols))\nprint(\"The total number of numerical columns:\", len(numerical_cols))\n\n\nThe total number of categorical columns: 40\nThe total number of numerical columns: 37\n\n\n\n\nCode\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_test= X_test[my_cols].copy()\n\n\nX_final = df_test[my_cols].copy()",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#pipelines-for-data-preprocessing",
    "href": "regression/5 XGboost on house price data.html#pipelines-for-data-preprocessing",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "2.5 Pipelines for Data Preprocessing",
    "text": "2.5 Pipelines for Data Preprocessing\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nnumerical_transformer = Pipeline(steps=[\n    ('imputer_num', SimpleImputer(strategy='median')), \n    ('scaler', StandardScaler())\n])\n\n\n\n\nCode\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer_cat', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)])",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#define-model",
    "href": "regression/5 XGboost on house price data.html#define-model",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.1 define model",
    "text": "3.1 define model\nrandom forest with hyper parameter tuning\n\n\nCode\nimport xgboost\nprint(xgboost.__version__)\n\n\n2.0.3\n\n\nrandom forest with hyper parameter tuning\n\n\nCode\nfrom xgboost import XGBRegressor\n\nml_model = XGBRegressor()\nml_model\n\n\nXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org. XGBRegressoriNot fittedXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#define-pipline",
    "href": "regression/5 XGboost on house price data.html#define-pipline",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.2 define pipline",
    "text": "3.2 define pipline\n\n\nCode\npipeline = Pipeline(\n  steps=[\n         ('preprocessor', preprocessor), \n         ('model', ml_model)\n         ]\n)",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#hyperparameter-tuning-set",
    "href": "regression/5 XGboost on house price data.html#hyperparameter-tuning-set",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.3 hyperparameter tuning set",
    "text": "3.3 hyperparameter tuning set\n\n\nCode\nfrom sklearn.model_selection import GridSearchCV\n\n\nparam_grid = {\n        'model__learning_rate': [0.01, 0.1],\n        'model__max_depth': [3, 5, 7, 10],\n        'model__min_child_weight': [1, 3, 5],\n        'model__subsample': [0.5, 0.7],\n       # 'model__colsample__bytree': [0.5, 0.7],\n        'model__n_estimators' : [100, 200, 500],\n        'model__objective': ['reg:squarederror']\n    }\n\n\n\n\nCode\nGridCV = GridSearchCV(pipeline, param_grid, n_jobs= -1, verbose=1)",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#train-model",
    "href": "regression/5 XGboost on house price data.html#train-model",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.4 train model",
    "text": "3.4 train model\n\n\nCode\nGridCV.fit(X_train, Y_train)\n\n\nFitting 5 folds for each of 144 candidates, totalling 720 fits\n\n\nGridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('imputer_num',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('scaler',\n                                                                                          StandardScaler())]),\n                                                                         ['Id',\n                                                                          'MSSubClass',\n                                                                          'LotFrontage',\n                                                                          'LotArea',\n                                                                          'OverallQual',\n                                                                          'OverallCond',\n                                                                          'YearBuilt',\n                                                                          'YearRemodAdd',\n                                                                          'MasVnrArea',\n                                                                          'BsmtFinSF1',\n                                                                          'BsmtFinSF2',\n                                                                          'BsmtUnfSF',\n                                                                          'TotalBsmtSF...\n                                                     monotone_constraints=None,\n                                                     multi_strategy=None,\n                                                     n_estimators=None,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={'model__learning_rate': [0.01, 0.1],\n                         'model__max_depth': [3, 5, 7, 10],\n                         'model__min_child_weight': [1, 3, 5],\n                         'model__n_estimators': [100, 200, 500],\n                         'model__objective': ['reg:squarederror'],\n                         'model__subsample': [0.5, 0.7]},\n             verbose=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GridSearchCV?Documentation for GridSearchCViFittedGridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('imputer_num',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('scaler',\n                                                                                          StandardScaler())]),\n                                                                         ['Id',\n                                                                          'MSSubClass',\n                                                                          'LotFrontage',\n                                                                          'LotArea',\n                                                                          'OverallQual',\n                                                                          'OverallCond',\n                                                                          'YearBuilt',\n                                                                          'YearRemodAdd',\n                                                                          'MasVnrArea',\n                                                                          'BsmtFinSF1',\n                                                                          'BsmtFinSF2',\n                                                                          'BsmtUnfSF',\n                                                                          'TotalBsmtSF...\n                                                     monotone_constraints=None,\n                                                     multi_strategy=None,\n                                                     n_estimators=None,\n                                                     n_jobs=None,\n                                                     num_parallel_tree=None,\n                                                     random_state=None, ...))]),\n             n_jobs=-1,\n             param_grid={'model__learning_rate': [0.01, 0.1],\n                         'model__max_depth': [3, 5, 7, 10],\n                         'model__min_child_weight': [1, 3, 5],\n                         'model__n_estimators': [100, 200, 500],\n                         'model__objective': ['reg:squarederror'],\n                         'model__subsample': [0.5, 0.7]},\n             verbose=1) estimator: PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                              feature_types=None, gamma=None, grow_policy=None,\n                              importance_type=None,\n                              interaction_constraints=None, learning_rate=None,\n                              max_bin=None, max_cat_threshold=None,\n                              max_cat_to_onehot=None, max_delta_step=None,\n                              max_depth=None, max_leaves=None,\n                              min_child_weight=None, missing=nan,\n                              monotone_constraints=None, multi_strategy=None,\n                              n_estimators=None, n_jobs=None,\n                              num_parallel_tree=None, random_state=None, ...))])  preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer_num',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 ['Id', 'MSSubClass', 'LotFrontage', 'LotArea',\n                                  'OverallQual', 'OverallCond', 'YearBuilt',\n                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n                                  'GrLivArea', 'Bsm...\n                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n                                  'LandContour', 'Utilities', 'LotConfig',\n                                  'LandSlope', 'Condition1', 'Condition2',\n                                  'BldgType', 'HouseStyle', 'RoofStyle',\n                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n                                  'ExterCond', 'Foundation', 'BsmtQual',\n                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n                                  'CentralAir', 'Electrical', 'KitchenQual',\n                                  'Functional', 'FireplaceQu', ...])]) num['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median')  StandardScaler?Documentation for StandardScalerStandardScaler() cat['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent')  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore') XGBRegressorXGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=None, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=None,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...) \n\n\n\n\nCode\nGridCV.best_params_\n\n\n{'model__learning_rate': 0.1,\n 'model__max_depth': 5,\n 'model__min_child_weight': 3,\n 'model__n_estimators': 500,\n 'model__objective': 'reg:squarederror',\n 'model__subsample': 0.7}\n\n\n\n\nCode\nGridCV.best_score_\n\n\n0.8615001834952437\n\n\nbest model as pipeline\n\n\nCode\noptimised_model_pipeline = GridCV.best_estimator_\n\n\n\n\nCode\nvar=optimised_model_pipeline[:-1].get_feature_names_out()\n#var\n\n\n\n\nCode\nfitted_model=optimised_model_pipeline.steps[1][1]\n\n\nvariable importance\n\n\nCode\nimportances = fitted_model.feature_importances_\nvi=pd.DataFrame({\"variable\":var,\"importances\":importances})\nvi=vi.sort_values('importances',ascending=False)\nvi\n\n\n\n\n\n\n\n\n\n\nvariable\nimportances\n\n\n\n\n4\nnum__OverallQual\n0.297115\n\n\n124\ncat__BsmtQual_Ex\n0.087956\n\n\n166\ncat__KitchenQual_Ex\n0.072809\n\n\n26\nnum__GarageCars\n0.039860\n\n\n41\ncat__MSZoning_RM\n0.030917\n\n\n...\n...\n...\n\n\n77\ncat__Condition2_PosN\n0.000000\n\n\n164\ncat__Electrical_Mix\n0.000000\n\n\n163\ncat__Electrical_FuseP\n0.000000\n\n\n78\ncat__Condition2_RRAe\n0.000000\n\n\n72\ncat__Condition1_RRNn\n0.000000\n\n\n\n\n230 rows × 2 columns",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#preformance",
    "href": "regression/5 XGboost on house price data.html#preformance",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.5 Preformance",
    "text": "3.5 Preformance\n\n\nCode\nY_pred_dt =optimised_model_pipeline.predict(X_test) #always gets x and retuns y\n\n\nR 2\n\n\nCode\nfrom sklearn.metrics import r2_score\nr2_score(Y_test, Y_pred_dt)\n\n\n0.8839026641970225\n\n\nMAE\n\n\nCode\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(Y_test, Y_pred_dt)\n\n\n16853.850478916953\n\n\nRMSE\n\n\nCode\nfrom  math import sqrt\nfrom sklearn.metrics import mean_squared_error\nmse=mean_squared_error(Y_test, Y_pred_dt)\nrmse=sqrt(mse)\nrmse\n\n\n28272.631597361225",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/5 XGboost on house price data.html#k-fold-cross-validation",
    "href": "regression/5 XGboost on house price data.html#k-fold-cross-validation",
    "title": "XGboost and pipeline, hyperparameter tuning",
    "section": "3.6 k-Fold Cross-Validation",
    "text": "3.6 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \n\n\n\n\nCode\ncv_dt = cross_val_score(optimised_model_pipeline, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.8655940377808318\n\n\n\n\nCode\ncv_dt = cross_val_score(optimised_model_pipeline, X_train, Y_train, cv=kf_dt,scoring = 'neg_mean_squared_error')\nnp.mean(np.sqrt(np.abs(cv_dt)))\n\n\n28039.92759053607",
    "crumbs": [
      "Regression",
      "XGboost and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#download-data",
    "href": "regression/0 house price data.html#download-data",
    "title": "Housing Prices Dataset",
    "section": "2.1 download data",
    "text": "2.1 download data\nhttps://www.kaggle.com/competitions/house-prices-advanced-regression-techniques",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#input-data",
    "href": "regression/0 house price data.html#input-data",
    "title": "Housing Prices Dataset",
    "section": "2.2 input data",
    "text": "2.2 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nId = df_train['Id']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\n\n\nCode\n#df_train.info()\n\n\n\n\nCode\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['SalePrice'], axis=1), df_test])",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#data-eda",
    "href": "regression/0 house price data.html#data-eda",
    "title": "Housing Prices Dataset",
    "section": "2.3 data EDA",
    "text": "2.3 data EDA\n\n\nCode\ndf_train.describe()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nLotFrontage\nLotArea\nOverallQual\nOverallCond\nYearBuilt\nYearRemodAdd\nMasVnrArea\nBsmtFinSF1\n...\nWoodDeckSF\nOpenPorchSF\nEnclosedPorch\n3SsnPorch\nScreenPorch\nPoolArea\nMiscVal\nMoSold\nYrSold\nSalePrice\n\n\n\n\ncount\n1460.000000\n1460.000000\n1201.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1452.000000\n1460.000000\n...\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n1460.000000\n\n\nmean\n730.500000\n56.897260\n70.049958\n10516.828082\n6.099315\n5.575342\n1971.267808\n1984.865753\n103.685262\n443.639726\n...\n94.244521\n46.660274\n21.954110\n3.409589\n15.060959\n2.758904\n43.489041\n6.321918\n2007.815753\n180921.195890\n\n\nstd\n421.610009\n42.300571\n24.284752\n9981.264932\n1.382997\n1.112799\n30.202904\n20.645407\n181.066207\n456.098091\n...\n125.338794\n66.256028\n61.119149\n29.317331\n55.757415\n40.177307\n496.123024\n2.703626\n1.328095\n79442.502883\n\n\nmin\n1.000000\n20.000000\n21.000000\n1300.000000\n1.000000\n1.000000\n1872.000000\n1950.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n1.000000\n2006.000000\n34900.000000\n\n\n25%\n365.750000\n20.000000\n59.000000\n7553.500000\n5.000000\n5.000000\n1954.000000\n1967.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n5.000000\n2007.000000\n129975.000000\n\n\n50%\n730.500000\n50.000000\n69.000000\n9478.500000\n6.000000\n5.000000\n1973.000000\n1994.000000\n0.000000\n383.500000\n...\n0.000000\n25.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n6.000000\n2008.000000\n163000.000000\n\n\n75%\n1095.250000\n70.000000\n80.000000\n11601.500000\n7.000000\n6.000000\n2000.000000\n2004.000000\n166.000000\n712.250000\n...\n168.000000\n68.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n8.000000\n2009.000000\n214000.000000\n\n\nmax\n1460.000000\n190.000000\n313.000000\n215245.000000\n10.000000\n9.000000\n2010.000000\n2010.000000\n1600.000000\n5644.000000\n...\n857.000000\n547.000000\n552.000000\n508.000000\n480.000000\n738.000000\n15500.000000\n12.000000\n2010.000000\n755000.000000\n\n\n\n\n8 rows × 38 columns\n\n\n\n\n\n\nCode\ndf_train.describe(include=[object])\n\n\n\n\n\n\n\n\n\n\nMSZoning\nStreet\nAlley\nLotShape\nLandContour\nUtilities\nLotConfig\nLandSlope\nNeighborhood\nCondition1\n...\nGarageFinish\nGarageQual\nGarageCond\nPavedDrive\nPoolQC\nFence\nMiscFeature\nSaleType\nSaleCondition\nrole\n\n\n\n\ncount\n1460\n1460\n91\n1460\n1460\n1460\n1460\n1460\n1460\n1460\n...\n1379\n1379\n1379\n1460\n7\n281\n54\n1460\n1460\n1460\n\n\nunique\n5\n2\n2\n4\n4\n2\n5\n3\n25\n9\n...\n3\n5\n5\n3\n3\n4\n4\n9\n6\n1\n\n\ntop\nRL\nPave\nGrvl\nReg\nLvl\nAllPub\nInside\nGtl\nNAmes\nNorm\n...\nUnf\nTA\nTA\nY\nGd\nMnPrv\nShed\nWD\nNormal\ntrain\n\n\nfreq\n1151\n1454\n50\n925\n1311\n1459\n1052\n1382\n225\n1260\n...\n605\n1311\n1326\n1340\n3\n157\n49\n1267\n1198\n1460\n\n\n\n\n4 rows × 44 columns\n\n\n\n\nMissing Data\n\n\nCode\ndf_train.isnull().sum()\n\n\nId                 0\nMSSubClass         0\nMSZoning           0\nLotFrontage      259\nLotArea            0\n                ... \nYrSold             0\nSaleType           0\nSaleCondition      0\nSalePrice          0\nrole               0\nLength: 82, dtype: int64\n\n\n\n\nCode\nimport seaborn as sns\nsns.histplot(data=df_train,x='SalePrice')\n\n\n\n\n\n\n\n\n\n\n\nCode\nimport sweetviz as sv\nmy_report = sv.analyze(df_train)\n\n\n\n\n\n\n\nCode\nmy_report.show_notebook()",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#feature-vs-target",
    "href": "regression/0 house price data.html#feature-vs-target",
    "title": "Housing Prices Dataset",
    "section": "2.4 feature vs target",
    "text": "2.4 feature vs target\n\n\nCode\nmy_report2 = sv.analyze(df_train,target_feat='SalePrice')\n\n\n\n\n\n\n\nCode\nmy_report2.show_notebook()",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#compare-train-data-and-test-data",
    "href": "regression/0 house price data.html#compare-train-data-and-test-data",
    "title": "Housing Prices Dataset",
    "section": "2.5 compare train data and test data",
    "text": "2.5 compare train data and test data\n\n\nCode\ncompare = sv.compare(source=df_train, compare=df_test)\n\n\n\n\n\n\n\nCode\ncompare.show_notebook()",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "regression/0 house price data.html#data-dictionary",
    "href": "regression/0 house price data.html#data-dictionary",
    "title": "Housing Prices Dataset",
    "section": "2.6 data dictionary",
    "text": "2.6 data dictionary\nSalePrice - the property’s sale price in dollars. This is the target variable that you’re trying to predict.\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: $Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale",
    "crumbs": [
      "Regression",
      "Housing Prices Dataset"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html",
    "href": "plot/2 plotnine.html",
    "title": "plotnine chart",
    "section": "",
    "text": "plotnine is an implementation of a grammar of graphics in Python based on ggplot2.\nCode\nfrom plotnine import *\nimport seaborn as sns\n\n\n# Apply the default theme\n\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#color-by-group",
    "href": "plot/2 plotnine.html#color-by-group",
    "title": "plotnine chart",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\np=(\n    ggplot(data=tips)+aes(x=\"tip\",y=\"total_bill\")+ geom_point(aes(color=\"sex\"))\n)\n\np",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#size-by-group",
    "href": "plot/2 plotnine.html#size-by-group",
    "title": "plotnine chart",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\np=(\n    ggplot(data=tips)+aes(x=\"tip\",y=\"total_bill\",size=\"size\")+ geom_point()\n)\n\np",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#color-by-group-1",
    "href": "plot/2 plotnine.html#color-by-group-1",
    "title": "plotnine chart",
    "section": "2.1 color by group",
    "text": "2.1 color by group\n\n\nCode\np=(\n    ggplot(data=tips)+aes(x=\"tip\",y=\"total_bill\")+ geom_line(aes(color=\"sex\"))\n)\n\np",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#color-by-group-2",
    "href": "plot/2 plotnine.html#color-by-group-2",
    "title": "plotnine chart",
    "section": "3.1 color by group",
    "text": "3.1 color by group\n\n\nCode\np=(\n    ggplot(data=tips)+aes(x=\"tip\",fill = 'sex')+ geom_histogram(position = 'dodge')\n)\n\np",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#color-by-group-3",
    "href": "plot/2 plotnine.html#color-by-group-3",
    "title": "plotnine chart",
    "section": "5.1 color by group",
    "text": "5.1 color by group",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "plot/2 plotnine.html#color-by-group-4",
    "href": "plot/2 plotnine.html#color-by-group-4",
    "title": "plotnine chart",
    "section": "6.1 color by group",
    "text": "6.1 color by group",
    "crumbs": [
      "Plot",
      "plotnine chart"
    ]
  },
  {
    "objectID": "home/3 install package.html",
    "href": "home/3 install package.html",
    "title": "install pacakge",
    "section": "",
    "text": "1 package\n\n\nCode\nimport os\nos.system('pip install -U scikit-learn')\n\n\n\n\n2 package version\n\n\nCode\nimport sklearn\nsklearn.show_versions()\n\n\n\nSystem:\n    python: 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\nexecutable: /Library/Frameworks/Python.framework/Versions/3.11/bin/python3\n   machine: macOS-14.1.1-arm64-arm-64bit\n\nPython dependencies:\n      sklearn: 1.4.1.post1\n          pip: 24.0\n   setuptools: 65.5.0\n        numpy: 1.26.4\n        scipy: 1.12.0\n       Cython: None\n       pandas: 2.2.1\n   matplotlib: 3.8.3\n       joblib: 1.3.2\nthreadpoolctl: 3.2.0\n\nBuilt with OpenMP: True\n\nthreadpoolctl info:\n       user_api: blas\n   internal_api: openblas\n    num_threads: 8\n         prefix: libopenblas\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/.dylibs/libopenblas64_.0.dylib\n        version: 0.3.23.dev\nthreading_layer: pthreads\n   architecture: armv8\n\n       user_api: openmp\n   internal_api: openmp\n    num_threads: 8\n         prefix: libomp\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/.dylibs/libomp.dylib\n        version: None\n\n       user_api: blas\n   internal_api: openblas\n    num_threads: 8\n         prefix: libopenblas\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/.dylibs/libopenblas.0.dylib\n        version: 0.3.21.dev\nthreading_layer: pthreads\n   architecture: armv8",
    "crumbs": [
      "Home",
      "install pacakge"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html",
    "href": "classification/1 decision tree on titanic data.html",
    "title": "Classification with decision tree",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#input-data",
    "href": "classification/1 decision tree on titanic data.html#input-data",
    "title": "Classification with decision tree",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#data-eda",
    "href": "classification/1 decision tree on titanic data.html#data-eda",
    "title": "Classification with decision tree",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\n\n\nCode\nsns.countplot(x='Survived', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())\n\n\n0.7420382165605095\n0.18890814558058924",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#data-wrangling",
    "href": "classification/1 decision tree on titanic data.html#data-wrangling",
    "title": "Classification with decision tree",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n\nCode\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n\n\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1046 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1308 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Dealing with missing numerical variables\ndata['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\n\n# Check out info of data\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1309 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1309 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Tranform Sex feature to numeric value\n# create a new column for each of the options in 'Sex'\n# creates a new column for female, called 'Sex_female', \n# creates a new column for 'Sex_male'\n# more then two categorical values it is better to use one-hot-encode\ndata = pd.get_dummies(data, columns=['Sex'], drop_first=True)\ndata.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nrole\nSex_male\n\n\n\n\n0\n1\n3\nBraund, Mr. Owen Harris\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\ntrain\nTrue\n\n\n1\n2\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\ntrain\nFalse\n\n\n2\n3\n3\nHeikkinen, Miss. Laina\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\ntrain\nFalse\n\n\n3\n4\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n35.0\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nFalse\n\n\n4\n5\n3\nAllen, Mr. William Henry\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\ntrain\nTrue\n\n\n\n\n\n\n\n\n\n\nCode\n# Select features columns\ndata = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp','role']]\ndata.head()\n\n\n\n\n\n\n\n\n\n\nSex_male\nFare\nAge\nPclass\nSibSp\nrole\n\n\n\n\n0\nTrue\n7.2500\n22.0\n3\n1\ntrain\n\n\n1\nFalse\n71.2833\n38.0\n1\n1\ntrain\n\n\n2\nFalse\n7.9250\n26.0\n3\n0\ntrain\n\n\n3\nFalse\n53.1000\n35.0\n1\n1\ntrain\n\n\n4\nTrue\n8.0500\n35.0\n3\n0\ntrain",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#split-data",
    "href": "classification/1 decision tree on titanic data.html#split-data",
    "title": "Classification with decision tree",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY=df_train['Survived']\nX=data[data.role =='train']\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nX_train.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 712 entries, 195 to 652\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Sex_male  712 non-null    bool   \n 1   Fare      712 non-null    float64\n 2   Age       712 non-null    float64\n 3   Pclass    712 non-null    int64  \n 4   SibSp     712 non-null    int64  \ndtypes: bool(1), float64(2), int64(2)\nmemory usage: 28.5 KB",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#define-model",
    "href": "classification/1 decision tree on titanic data.html#define-model",
    "title": "Classification with decision tree",
    "section": "3.1 define model",
    "text": "3.1 define model\n\n\nCode\nmodel_dt = tree.DecisionTreeClassifier(max_depth=3)   #model with deph 3\nmodel_dt\n\n\nDecisionTreeClassifier(max_depth=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriNot fittedDecisionTreeClassifier(max_depth=3)",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#train-model",
    "href": "classification/1 decision tree on titanic data.html#train-model",
    "title": "Classification with decision tree",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nmodel_dt.fit(X_train,Y_train)\n\n\nDecisionTreeClassifier(max_depth=3)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(max_depth=3) \n\n\nvariable importance\n\n\nCode\nimportances = model_dt.feature_importances_\nvi=pd.DataFrame({\"variable\":X_train.columns,\"importances\":importances})\nvi=vi.sort_values('importances',ascending=False)\nvi\n\n\n\n\n\n\n\n\n\n\nvariable\nimportances\n\n\n\n\n0\nSex_male\n0.637877\n\n\n3\nPclass\n0.129970\n\n\n1\nFare\n0.098846\n\n\n4\nSibSp\n0.071764\n\n\n2\nAge\n0.061543",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#preformance",
    "href": "classification/1 decision tree on titanic data.html#preformance",
    "title": "Classification with decision tree",
    "section": "3.3 Preformance",
    "text": "3.3 Preformance\n\n\nCode\n#Using predict method to test the model\nY_pred_dt = model_dt.predict(X_test) #always gets x and retuns y\n\n\n\nAccuracy\n\n\n\nCode\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  \naccuracy\n\n\n0.8044692737430168\n\n\n\nPrecision\n\n\n\nCode\n# Precision = true positive / true positive + false positive\nprecision_dt = metrics.precision_score(Y_test,Y_pred_dt)  \nprecision_dt\n\n\n0.8028169014084507\n\n\n\nRecall\n\n\n\nCode\n# Recall = true positive / true positive + false negative\nrecall_dt = metrics.recall_score(Y_test,Y_pred_dt)  \nrecall_dt\n\n\n0.7307692307692307\n\n\n\nConfusion matrix\n\n\n\nCode\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)\nconfusion_matrix_dt\n\n\narray([[87, 14],\n       [21, 57]])\n\n\n\nAUC - ROC Curve\n\n\n\nCode\nauc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score\nauc_dt\n\n\n0.796077684691546",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/1 decision tree on titanic data.html#k-fold-cross-validation",
    "href": "classification/1 decision tree on titanic data.html#k-fold-cross-validation",
    "title": "Classification with decision tree",
    "section": "3.4 k-Fold Cross-Validation",
    "text": "3.4 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \ncv_dt = cross_val_score(model_dt, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.824367182113661",
    "crumbs": [
      "Classification",
      "Classification with decision tree"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html",
    "href": "classification/3 Support Vector Machines on titanic data.html",
    "title": "Classification with Support Vector Machines",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#input-data",
    "href": "classification/3 Support Vector Machines on titanic data.html#input-data",
    "title": "Classification with Support Vector Machines",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#data-eda",
    "href": "classification/3 Support Vector Machines on titanic data.html#data-eda",
    "title": "Classification with Support Vector Machines",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\n\n\nCode\nsns.countplot(x='Survived', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())\n\n\n0.7420382165605095\n0.18890814558058924",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#data-wrangling",
    "href": "classification/3 Support Vector Machines on titanic data.html#data-wrangling",
    "title": "Classification with Support Vector Machines",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n\nCode\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n\n\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1046 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1308 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Dealing with missing numerical variables\ndata['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\n\n# Check out info of data\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1309 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1309 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Tranform Sex feature to numeric value\n# create a new column for each of the options in 'Sex'\n# creates a new column for female, called 'Sex_female', \n# creates a new column for 'Sex_male'\n# more then two categorical values it is better to use one-hot-encode\ndata = pd.get_dummies(data, columns=['Sex'], drop_first=True)\ndata.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nrole\nSex_male\n\n\n\n\n0\n1\n3\nBraund, Mr. Owen Harris\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\ntrain\nTrue\n\n\n1\n2\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\ntrain\nFalse\n\n\n2\n3\n3\nHeikkinen, Miss. Laina\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\ntrain\nFalse\n\n\n3\n4\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n35.0\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nFalse\n\n\n4\n5\n3\nAllen, Mr. William Henry\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\ntrain\nTrue\n\n\n\n\n\n\n\n\n\n\nCode\n# Select features columns\ndata = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp','role']]\ndata.head()\n\n\n\n\n\n\n\n\n\n\nSex_male\nFare\nAge\nPclass\nSibSp\nrole\n\n\n\n\n0\nTrue\n7.2500\n22.0\n3\n1\ntrain\n\n\n1\nFalse\n71.2833\n38.0\n1\n1\ntrain\n\n\n2\nFalse\n7.9250\n26.0\n3\n0\ntrain\n\n\n3\nFalse\n53.1000\n35.0\n1\n1\ntrain\n\n\n4\nTrue\n8.0500\n35.0\n3\n0\ntrain",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#split-data",
    "href": "classification/3 Support Vector Machines on titanic data.html#split-data",
    "title": "Classification with Support Vector Machines",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY=df_train['Survived']\nX=data[data.role =='train']\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nX_train.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 712 entries, 64 to 775\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Sex_male  712 non-null    bool   \n 1   Fare      712 non-null    float64\n 2   Age       712 non-null    float64\n 3   Pclass    712 non-null    int64  \n 4   SibSp     712 non-null    int64  \ndtypes: bool(1), float64(2), int64(2)\nmemory usage: 28.5 KB",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#define-model",
    "href": "classification/3 Support Vector Machines on titanic data.html#define-model",
    "title": "Classification with Support Vector Machines",
    "section": "3.1 define model",
    "text": "3.1 define model\nThe solvers implemented in the class Logistic Regression are “liblinear”, “newton-cg”, “lbfgs”, “sag” and “saga”. According to Scikit Documentation: The “liblinear” solver was the one used by default for historical reasons before version 0.22. Since then, default use is lbfgs Algorithm.\n\n\nCode\nfrom sklearn import svm\nml_model = svm.SVC(kernel=\"linear\")\nml_model\n\n\nSVC(kernel='linear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiNot fittedSVC(kernel='linear')",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#train-model",
    "href": "classification/3 Support Vector Machines on titanic data.html#train-model",
    "title": "Classification with Support Vector Machines",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nml_model.fit(X_train,Y_train)\n\n\nSVC(kernel='linear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  SVC?Documentation for SVCiFittedSVC(kernel='linear')",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#preformance",
    "href": "classification/3 Support Vector Machines on titanic data.html#preformance",
    "title": "Classification with Support Vector Machines",
    "section": "3.3 Preformance",
    "text": "3.3 Preformance\n\n\nCode\n#Using predict method to test the model\nY_pred_dt = ml_model.predict(X_test) #always gets x and retuns y\n\n\n\nAccuracy\n\n\n\nCode\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  \naccuracy\n\n\n0.776536312849162\n\n\n\nPrecision\n\n\n\nCode\n# Precision = true positive / true positive + false positive\nprecision_dt = metrics.precision_score(Y_test,Y_pred_dt)  \nprecision_dt\n\n\n0.7083333333333334\n\n\n\nRecall\n\n\n\nCode\n# Recall = true positive / true positive + false negative\nrecall_dt = metrics.recall_score(Y_test,Y_pred_dt)  \nrecall_dt\n\n\n0.7285714285714285\n\n\n\nConfusion matrix\n\n\n\nCode\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)\nconfusion_matrix_dt\n\n\narray([[88, 21],\n       [19, 51]])\n\n\n\nAUC - ROC Curve\n\n\n\nCode\nauc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score\nauc_dt\n\n\n0.7679554390563565",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/3 Support Vector Machines on titanic data.html#k-fold-cross-validation",
    "href": "classification/3 Support Vector Machines on titanic data.html#k-fold-cross-validation",
    "title": "Classification with Support Vector Machines",
    "section": "3.4 k-Fold Cross-Validation",
    "text": "3.4 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \ncv_dt = cross_val_score(ml_model, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.7893036540923866",
    "crumbs": [
      "Classification",
      "Classification with Support Vector Machines"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html",
    "href": "classification/2 Logistic Regression on titanic data.html",
    "title": "Classification with Logistic Regression",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#input-data",
    "href": "classification/2 Logistic Regression on titanic data.html#input-data",
    "title": "Classification with Logistic Regression",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#data-eda",
    "href": "classification/2 Logistic Regression on titanic data.html#data-eda",
    "title": "Classification with Logistic Regression",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\n\n\nCode\nsns.countplot(x='Survived', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())\n\n\n0.7420382165605095\n0.18890814558058924",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#data-wrangling",
    "href": "classification/2 Logistic Regression on titanic data.html#data-wrangling",
    "title": "Classification with Logistic Regression",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n\nCode\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n\n\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1046 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1308 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Dealing with missing numerical variables\ndata['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\n\n# Check out info of data\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1309 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1309 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Tranform Sex feature to numeric value\n# create a new column for each of the options in 'Sex'\n# creates a new column for female, called 'Sex_female', \n# creates a new column for 'Sex_male'\n# more then two categorical values it is better to use one-hot-encode\ndata = pd.get_dummies(data, columns=['Sex'], drop_first=True)\ndata.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nrole\nSex_male\n\n\n\n\n0\n1\n3\nBraund, Mr. Owen Harris\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\ntrain\nTrue\n\n\n1\n2\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\ntrain\nFalse\n\n\n2\n3\n3\nHeikkinen, Miss. Laina\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\ntrain\nFalse\n\n\n3\n4\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n35.0\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nFalse\n\n\n4\n5\n3\nAllen, Mr. William Henry\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\ntrain\nTrue\n\n\n\n\n\n\n\n\n\n\nCode\n# Select features columns\ndata = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp','role']]\ndata.head()\n\n\n\n\n\n\n\n\n\n\nSex_male\nFare\nAge\nPclass\nSibSp\nrole\n\n\n\n\n0\nTrue\n7.2500\n22.0\n3\n1\ntrain\n\n\n1\nFalse\n71.2833\n38.0\n1\n1\ntrain\n\n\n2\nFalse\n7.9250\n26.0\n3\n0\ntrain\n\n\n3\nFalse\n53.1000\n35.0\n1\n1\ntrain\n\n\n4\nTrue\n8.0500\n35.0\n3\n0\ntrain",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#split-data",
    "href": "classification/2 Logistic Regression on titanic data.html#split-data",
    "title": "Classification with Logistic Regression",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY=df_train['Survived']\nX=data[data.role =='train']\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nX_train.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 712 entries, 161 to 472\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Sex_male  712 non-null    bool   \n 1   Fare      712 non-null    float64\n 2   Age       712 non-null    float64\n 3   Pclass    712 non-null    int64  \n 4   SibSp     712 non-null    int64  \ndtypes: bool(1), float64(2), int64(2)\nmemory usage: 28.5 KB",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#define-model",
    "href": "classification/2 Logistic Regression on titanic data.html#define-model",
    "title": "Classification with Logistic Regression",
    "section": "3.1 define model",
    "text": "3.1 define model\nThe solvers implemented in the class Logistic Regression are “liblinear”, “newton-cg”, “lbfgs”, “sag” and “saga”. According to Scikit Documentation: The “liblinear” solver was the one used by default for historical reasons before version 0.22. Since then, default use is lbfgs Algorithm.\n\n\nCode\nfrom sklearn.linear_model import LogisticRegression\nml_model = LogisticRegression(solver='liblinear')\nml_model\n\n\nLogisticRegression(solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniNot fittedLogisticRegression(solver='liblinear')",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#train-model",
    "href": "classification/2 Logistic Regression on titanic data.html#train-model",
    "title": "Classification with Logistic Regression",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nml_model.fit(X_train,Y_train)\n\n\nLogisticRegression(solver='liblinear')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LogisticRegression?Documentation for LogisticRegressioniFittedLogisticRegression(solver='liblinear') \n\n\nvariable importance\n\n\nCode\ncoefficients = ml_model.coef_[0]\n\nfeature_importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': np.abs(coefficients)})\nfeature_importance = feature_importance.sort_values('Importance', ascending=False)\nfeature_importance\n\n\n\n\n\n\n\n\n\n\nFeature\nImportance\n\n\n\n\n0\nSex_male\n2.353789\n\n\n3\nPclass\n0.665656\n\n\n4\nSibSp\n0.320361\n\n\n2\nAge\n0.025501\n\n\n1\nFare\n0.006246",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#preformance",
    "href": "classification/2 Logistic Regression on titanic data.html#preformance",
    "title": "Classification with Logistic Regression",
    "section": "3.3 Preformance",
    "text": "3.3 Preformance\n\n\nCode\n#Using predict method to test the model\nY_pred_dt = ml_model.predict(X_test) #always gets x and retuns y\n\n\n\nAccuracy\n\n\n\nCode\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  \naccuracy\n\n\n0.8435754189944135\n\n\n\nPrecision\n\n\n\nCode\n# Precision = true positive / true positive + false positive\nprecision_dt = metrics.precision_score(Y_test,Y_pred_dt)  \nprecision_dt\n\n\n0.8245614035087719\n\n\n\nRecall\n\n\n\nCode\n# Recall = true positive / true positive + false negative\nrecall_dt = metrics.recall_score(Y_test,Y_pred_dt)  \nrecall_dt\n\n\n0.7230769230769231\n\n\n\nConfusion matrix\n\n\n\nCode\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)\nconfusion_matrix_dt\n\n\narray([[104,  10],\n       [ 18,  47]])\n\n\n\nAUC - ROC Curve\n\n\n\nCode\nauc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score\nauc_dt\n\n\n0.8176788124156545",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/2 Logistic Regression on titanic data.html#k-fold-cross-validation",
    "href": "classification/2 Logistic Regression on titanic data.html#k-fold-cross-validation",
    "title": "Classification with Logistic Regression",
    "section": "3.4 k-Fold Cross-Validation",
    "text": "3.4 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \ncv_dt = cross_val_score(ml_model, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.7794346498571851",
    "crumbs": [
      "Classification",
      "Classification with Logistic Regression"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html",
    "href": "classification/5 Random Forest on titanic dat.html",
    "title": "Classification with Random Forest",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#input-data",
    "href": "classification/5 Random Forest on titanic dat.html#input-data",
    "title": "Classification with Random Forest",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#data-eda",
    "href": "classification/5 Random Forest on titanic dat.html#data-eda",
    "title": "Classification with Random Forest",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\n\n\nCode\nsns.countplot(x='Survived', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())\n\n\n0.7420382165605095\n0.18890814558058924",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#data-wrangling",
    "href": "classification/5 Random Forest on titanic dat.html#data-wrangling",
    "title": "Classification with Random Forest",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n\nCode\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n\n\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1046 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1308 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Dealing with missing numerical variables\ndata['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\n\n# Check out info of data\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1309 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1309 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Tranform Sex feature to numeric value\n# create a new column for each of the options in 'Sex'\n# creates a new column for female, called 'Sex_female', \n# creates a new column for 'Sex_male'\n# more then two categorical values it is better to use one-hot-encode\ndata = pd.get_dummies(data, columns=['Sex'], drop_first=True)\ndata.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nrole\nSex_male\n\n\n\n\n0\n1\n3\nBraund, Mr. Owen Harris\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\ntrain\nTrue\n\n\n1\n2\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\ntrain\nFalse\n\n\n2\n3\n3\nHeikkinen, Miss. Laina\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\ntrain\nFalse\n\n\n3\n4\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n35.0\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nFalse\n\n\n4\n5\n3\nAllen, Mr. William Henry\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\ntrain\nTrue\n\n\n\n\n\n\n\n\n\n\nCode\n# Select features columns\ndata = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp','role']]\ndata.head()\n\n\n\n\n\n\n\n\n\n\nSex_male\nFare\nAge\nPclass\nSibSp\nrole\n\n\n\n\n0\nTrue\n7.2500\n22.0\n3\n1\ntrain\n\n\n1\nFalse\n71.2833\n38.0\n1\n1\ntrain\n\n\n2\nFalse\n7.9250\n26.0\n3\n0\ntrain\n\n\n3\nFalse\n53.1000\n35.0\n1\n1\ntrain\n\n\n4\nTrue\n8.0500\n35.0\n3\n0\ntrain",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#split-data",
    "href": "classification/5 Random Forest on titanic dat.html#split-data",
    "title": "Classification with Random Forest",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY=df_train['Survived']\nX=data[data.role =='train']\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nX_train.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 712 entries, 555 to 802\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Sex_male  712 non-null    bool   \n 1   Fare      712 non-null    float64\n 2   Age       712 non-null    float64\n 3   Pclass    712 non-null    int64  \n 4   SibSp     712 non-null    int64  \ndtypes: bool(1), float64(2), int64(2)\nmemory usage: 28.5 KB",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#define-model",
    "href": "classification/5 Random Forest on titanic dat.html#define-model",
    "title": "Classification with Random Forest",
    "section": "3.1 define model",
    "text": "3.1 define model\nThe solvers implemented in the class Logistic Regression are “liblinear”, “newton-cg”, “lbfgs”, “sag” and “saga”. According to Scikit Documentation: The “liblinear” solver was the one used by default for historical reasons before version 0.22. Since then, default use is lbfgs Algorithm.\n\n\nCode\nfrom sklearn.ensemble import RandomForestClassifier\nml_model = RandomForestClassifier()\nml_model\n\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriNot fittedRandomForestClassifier()",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#train-model",
    "href": "classification/5 Random Forest on titanic dat.html#train-model",
    "title": "Classification with Random Forest",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nml_model.fit(X_train,Y_train)\n\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier()",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#preformance",
    "href": "classification/5 Random Forest on titanic dat.html#preformance",
    "title": "Classification with Random Forest",
    "section": "3.3 Preformance",
    "text": "3.3 Preformance\n\n\nCode\n#Using predict method to test the model\nY_pred_dt = ml_model.predict(X_test) #always gets x and retuns y\nY_pred_dt\n\n\narray([0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n       1, 1, 1])\n\n\n\nAccuracy\n\n\n\nCode\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  \naccuracy\n\n\n0.8268156424581006\n\n\n\nPrecision\n\n\n\nCode\n# Precision = true positive / true positive + false positive\nprecision_dt = metrics.precision_score(Y_test,Y_pred_dt)  \nprecision_dt\n\n\n0.8070175438596491\n\n\n\nRecall\n\n\n\nCode\n# Recall = true positive / true positive + false negative\nrecall_dt = metrics.recall_score(Y_test,Y_pred_dt)  \nrecall_dt\n\n\n0.696969696969697\n\n\n\nConfusion matrix\n\n\n\nCode\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)\nconfusion_matrix_dt\n\n\narray([[102,  11],\n       [ 20,  46]])\n\n\n\nAUC - ROC Curve\n\n\n\nCode\nauc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score\nauc_dt\n\n\n0.799812282113167",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/5 Random Forest on titanic dat.html#k-fold-cross-validation",
    "href": "classification/5 Random Forest on titanic dat.html#k-fold-cross-validation",
    "title": "Classification with Random Forest",
    "section": "3.4 k-Fold Cross-Validation",
    "text": "3.4 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \ncv_dt = cross_val_score(ml_model, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.8216093765389539",
    "crumbs": [
      "Classification",
      "Classification with Random Forest"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html",
    "href": "classification/4 KNN on titanic data.html",
    "title": "Classification with K-Nearest Neighbors",
    "section": "",
    "text": "Code\nimport os\n#os.system('pip install xgboost')\n\n\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport numpy as np\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#input-data",
    "href": "classification/4 KNN on titanic data.html#input-data",
    "title": "Classification with K-Nearest Neighbors",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nPassengerId = df_train['PassengerId']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#data-eda",
    "href": "classification/4 KNN on titanic data.html#data-eda",
    "title": "Classification with K-Nearest Neighbors",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\n\n\nCode\nsns.countplot(x='Survived', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nsns.catplot(x='Survived', col='Sex', kind='count', data=df_train);\n\n\n\n\n\n\n\n\n\n\n\nCode\nprint(df_train[df_train.Sex == 'female'].Survived.sum()/df_train[df_train.Sex == 'female'].Survived.count())\nprint(df_train[df_train.Sex == 'male'].Survived.sum()/df_train[df_train.Sex == 'male'].Survived.count())\n\n\n0.7420382165605095\n0.18890814558058924",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#data-wrangling",
    "href": "classification/4 KNN on titanic data.html#data-wrangling",
    "title": "Classification with K-Nearest Neighbors",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling\n\n\nCode\n# Store target variable of training data in a safe place\nsurvived_train = df_train.Survived\n\n\n\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['Survived'], axis=1), df_test])\n\n\n\n\nCode\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1046 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1308 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Dealing with missing numerical variables\ndata['Age'] = data.Age.fillna(data.Age.median())\ndata['Fare'] = data.Fare.fillna(data.Fare.median())\n\n# Check out info of data\ndata.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 1309 entries, 0 to 417\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  1309 non-null   int64  \n 1   Pclass       1309 non-null   int64  \n 2   Name         1309 non-null   object \n 3   Sex          1309 non-null   object \n 4   Age          1309 non-null   float64\n 5   SibSp        1309 non-null   int64  \n 6   Parch        1309 non-null   int64  \n 7   Ticket       1309 non-null   object \n 8   Fare         1309 non-null   float64\n 9   Cabin        295 non-null    object \n 10  Embarked     1307 non-null   object \n 11  role         1309 non-null   object \ndtypes: float64(2), int64(4), object(6)\nmemory usage: 132.9+ KB\n\n\n\n\nCode\n# Tranform Sex feature to numeric value\n# create a new column for each of the options in 'Sex'\n# creates a new column for female, called 'Sex_female', \n# creates a new column for 'Sex_male'\n# more then two categorical values it is better to use one-hot-encode\ndata = pd.get_dummies(data, columns=['Sex'], drop_first=True)\ndata.head()\n\n\n\n\n\n\n\n\n\n\nPassengerId\nPclass\nName\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\nrole\nSex_male\n\n\n\n\n0\n1\n3\nBraund, Mr. Owen Harris\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\ntrain\nTrue\n\n\n1\n2\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\ntrain\nFalse\n\n\n2\n3\n3\nHeikkinen, Miss. Laina\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\ntrain\nFalse\n\n\n3\n4\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\n35.0\n1\n0\n113803\n53.1000\nC123\nS\ntrain\nFalse\n\n\n4\n5\n3\nAllen, Mr. William Henry\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\ntrain\nTrue\n\n\n\n\n\n\n\n\n\n\nCode\n# Select features columns\ndata = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp','role']]\ndata.head()\n\n\n\n\n\n\n\n\n\n\nSex_male\nFare\nAge\nPclass\nSibSp\nrole\n\n\n\n\n0\nTrue\n7.2500\n22.0\n3\n1\ntrain\n\n\n1\nFalse\n71.2833\n38.0\n1\n1\ntrain\n\n\n2\nFalse\n7.9250\n26.0\n3\n0\ntrain\n\n\n3\nFalse\n53.1000\n35.0\n1\n1\ntrain\n\n\n4\nTrue\n8.0500\n35.0\n3\n0\ntrain",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#split-data",
    "href": "classification/4 KNN on titanic data.html#split-data",
    "title": "Classification with K-Nearest Neighbors",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY=df_train['Survived']\nX=data[data.role =='train']\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nX_train.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 712 entries, 331 to 225\nData columns (total 5 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   Sex_male  712 non-null    bool   \n 1   Fare      712 non-null    float64\n 2   Age       712 non-null    float64\n 3   Pclass    712 non-null    int64  \n 4   SibSp     712 non-null    int64  \ndtypes: bool(1), float64(2), int64(2)\nmemory usage: 28.5 KB",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#define-model",
    "href": "classification/4 KNN on titanic data.html#define-model",
    "title": "Classification with K-Nearest Neighbors",
    "section": "3.1 define model",
    "text": "3.1 define model\nThe solvers implemented in the class Logistic Regression are “liblinear”, “newton-cg”, “lbfgs”, “sag” and “saga”. According to Scikit Documentation: The “liblinear” solver was the one used by default for historical reasons before version 0.22. Since then, default use is lbfgs Algorithm.\n\n\nCode\nfrom sklearn.neighbors import KNeighborsRegressor \nml_model = KNeighborsRegressor()\nml_model\n\n\nKNeighborsRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KNeighborsRegressor?Documentation for KNeighborsRegressoriNot fittedKNeighborsRegressor()",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#train-model",
    "href": "classification/4 KNN on titanic data.html#train-model",
    "title": "Classification with K-Nearest Neighbors",
    "section": "3.2 train model",
    "text": "3.2 train model\n\n\nCode\nml_model.fit(X_train,Y_train)\n\n\nKNeighborsRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KNeighborsRegressor?Documentation for KNeighborsRegressoriFittedKNeighborsRegressor()",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#preformance",
    "href": "classification/4 KNN on titanic data.html#preformance",
    "title": "Classification with K-Nearest Neighbors",
    "section": "3.3 Preformance",
    "text": "3.3 Preformance\n\n\nCode\n#Using predict method to test the model\nY_pred_dt = ml_model.predict(X_test) #always gets x and retuns y\nY_pred_dt\n\n\narray([0. , 0. , 0. , 0.2, 0.6, 0.8, 0.6, 0.2, 0.2, 0.6, 0.4, 0. , 0.2,\n       0.6, 0.8, 0.4, 0.2, 0. , 0.2, 0.4, 0.8, 0.8, 0.6, 0.2, 0.2, 0.8,\n       0.8, 0. , 1. , 0. , 0.6, 0.6, 0.2, 0.8, 0.8, 0.6, 0.2, 0.6, 0.4,\n       0.2, 0.6, 0.6, 0.6, 0. , 0.4, 0.2, 0.6, 0. , 0. , 0. , 0. , 0.2,\n       0. , 0. , 0.4, 0.6, 0. , 0.6, 0. , 0.2, 0.2, 0.2, 0. , 0.2, 0. ,\n       0.2, 0. , 0.2, 1. , 0.6, 0.4, 0.4, 0.8, 0.4, 0. , 0.2, 0.2, 0.2,\n       1. , 0.8, 0.2, 0. , 0.6, 0.8, 0. , 0.2, 0.4, 0. , 0.8, 0. , 0. ,\n       1. , 0. , 0.2, 0.4, 0.8, 0.4, 0.2, 0.6, 0.2, 0. , 0.2, 0.6, 0.2,\n       0. , 0. , 0.2, 0.4, 0. , 0.2, 0.4, 0.4, 0.2, 0. , 0.8, 0. , 0.8,\n       0.6, 0. , 0.6, 0.2, 0.6, 0.2, 0.2, 0.6, 0.8, 0. , 0.4, 0.6, 0. ,\n       0.2, 0.4, 0.4, 0.6, 0. , 0. , 0.6, 0.6, 0.2, 0.4, 1. , 0.2, 0.6,\n       0.2, 0.6, 0.6, 0.2, 0.8, 0.2, 0.8, 0.2, 0.2, 0.6, 0. , 0.6, 0.2,\n       0.8, 0.8, 1. , 0.2, 0.4, 0.2, 0. , 0.2, 0. , 0. , 0.2, 0.8, 0.8,\n       0.6, 0.2, 1. , 0. , 0.8, 0.2, 0.2, 0.8, 0.2, 0.2])\n\n\n\n\nCode\n# its criteria is to round to 1 when higher than 0.5\nY_pred_dt = np.round(Y_pred_dt)  \n\n\n\nAccuracy\n\n\n\nCode\n# Accuracy = true negatives + true positives / true positives + false positives + true negatives + false negatives\n# Here is another way to find the accuracy score\nfrom sklearn import metrics\naccuracy = metrics.accuracy_score(Y_test,Y_pred_dt)  \naccuracy\n\n\n0.6815642458100558\n\n\n\nPrecision\n\n\n\nCode\n# Precision = true positive / true positive + false positive\nprecision_dt = metrics.precision_score(Y_test,Y_pred_dt)  \nprecision_dt\n\n\n0.671875\n\n\n\nRecall\n\n\n\nCode\n# Recall = true positive / true positive + false negative\nrecall_dt = metrics.recall_score(Y_test,Y_pred_dt)  \nrecall_dt\n\n\n0.5443037974683544\n\n\n\nConfusion matrix\n\n\n\nCode\nimport seaborn as sns\nconfusion_matrix_dt = metrics.confusion_matrix(Y_test,Y_pred_dt)\nconfusion_matrix_dt\n\n\narray([[79, 21],\n       [36, 43]])\n\n\n\nAUC - ROC Curve\n\n\n\nCode\nauc_dt = metrics.roc_auc_score(Y_test, Y_pred_dt) # as the documentation explain, the main parameters are: y_true and y_score\nauc_dt\n\n\n0.6671518987341772",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "classification/4 KNN on titanic data.html#k-fold-cross-validation",
    "href": "classification/4 KNN on titanic data.html#k-fold-cross-validation",
    "title": "Classification with K-Nearest Neighbors",
    "section": "3.4 k-Fold Cross-Validation",
    "text": "3.4 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \ncv_dt = cross_val_score(ml_model, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.14586812998618273",
    "crumbs": [
      "Classification",
      "Classification with K-Nearest Neighbors"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#singular",
    "href": "home/4 data structure in Python .html#singular",
    "title": "data structure in Python",
    "section": "1.1 singular",
    "text": "1.1 singular\n\n\nCode\na=1\ntype(a)\n\n\nint\n\n\n\n\nCode\na=1.3\ntype(a)\n\n\nfloat\n\n\n\n\nCode\na='hell'\ntype(a)\n\n\nstr",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#list",
    "href": "home/4 data structure in Python .html#list",
    "title": "data structure in Python",
    "section": "1.2 list",
    "text": "1.2 list\n\n\nCode\na=[1,2,3]\n\na\n\n\n[1, 2, 3]\n\n\n\n\nCode\ntype(a) \n\n\nlist\n\n\n\n\nCode\nfruits = ['orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana','apple']\n\n\n\n1.2.1 find length of the list with len()\n\n\nCode\nlen(fruits)\n\n\n8\n\n\n\n\n1.2.2 find how many time in the list with count()\n\n\nCode\nfruits.count('apple')\n\n\n3\n\n\n\n\n1.2.3 find locaiton of on the list with index()\nshow the first ‘apple’ index. python list start at 0\n\n\nCode\nfruits.index('apple')\n\n\n1\n\n\nall ‘apple’ in the list\n\n\nCode\n[index for index, value in enumerate(fruits) if value == 'apple']\n\n\n[1, 5, 7]",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#reverse-the-list",
    "href": "home/4 data structure in Python .html#reverse-the-list",
    "title": "data structure in Python",
    "section": "1.3 reverse the list",
    "text": "1.3 reverse the list\n\n\nCode\nfruits.reverse()\nfruits\n\n\n['apple', 'banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange']\n\n\n\n1.3.1 sort the list\n\n\nCode\nfruits.sort()\nfruits\n\n\n['apple', 'apple', 'apple', 'banana', 'banana', 'kiwi', 'orange', 'pear']\n\n\n\n\n1.3.2 add element on the list\n\n\nCode\nfruits.append('grape')\nfruits\n\n\n['apple',\n 'apple',\n 'apple',\n 'banana',\n 'banana',\n 'kiwi',\n 'orange',\n 'pear',\n 'grape']",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#drop-last-element",
    "href": "home/4 data structure in Python .html#drop-last-element",
    "title": "data structure in Python",
    "section": "1.4 drop last element",
    "text": "1.4 drop last element\n\n\nCode\nfruits.pop()\n\nfruits\n\n\n['apple', 'apple', 'apple', 'banana', 'banana', 'kiwi', 'orange', 'pear']\n\n\n\n1.4.1 List Comprehensions\nusing loop:\n\n\nCode\nsquares = []\nfor x in range(10):\n  squares.append(x**2)\n  \nsquares\n\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nusing List Comprehensions\n\n\nCode\nsquares = [x**2 for x in range(10)]\nsquares\n\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#tuples",
    "href": "home/4 data structure in Python .html#tuples",
    "title": "data structure in Python",
    "section": "1.5 Tuples",
    "text": "1.5 Tuples\n\n\nCode\nfruits = ('orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana','apple')\n\nfruits\n\n\n('orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana', 'apple')\n\n\n\n\nCode\ntype(fruits)\n\n\ntuple\n\n\ntuple can not be modified.",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#sets",
    "href": "home/4 data structure in Python .html#sets",
    "title": "data structure in Python",
    "section": "1.6 Sets",
    "text": "1.6 Sets\nA set is an unordered collection with no duplicate elements.\n\n\nCode\nbasket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n\nbasket\n\n\n{'apple', 'banana', 'orange', 'pear'}\n\n\n\n\nCode\ntype(basket)\n\n\nset",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "home/4 data structure in Python .html#dictionaries",
    "href": "home/4 data structure in Python .html#dictionaries",
    "title": "data structure in Python",
    "section": "1.7 Dictionaries",
    "text": "1.7 Dictionaries\n\n\nCode\ntel = {'jack': 4098, 'sape': 4139}\n\ntel\n\n\n{'jack': 4098, 'sape': 4139}\n\n\n\n\nCode\ntype(tel)\n\n\ndict\n\n\n\n\nCode\ntel['jack']\n\n\n4098",
    "crumbs": [
      "Home",
      "data structure in Python"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html",
    "href": "plot/1 seaborn.html",
    "title": "seaborn chart",
    "section": "",
    "text": "Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\nCode\n# Import seaborn\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n\n# Apply the default theme\nsns.set_theme()\n\n# Load an example dataset\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n\n\n\n\n\n\n\n\n\ntotal_bill\ntip\nsex\nsmoker\nday\ntime\nsize\n\n\n\n\n0\n16.99\n1.01\nFemale\nNo\nSun\nDinner\n2\n\n\n1\n10.34\n1.66\nMale\nNo\nSun\nDinner\n3\n\n\n2\n21.01\n3.50\nMale\nNo\nSun\nDinner\n3\n\n\n3\n23.68\n3.31\nMale\nNo\nSun\nDinner\n2\n\n\n4\n24.59\n3.61\nFemale\nNo\nSun\nDinner\n4",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#color-by-group",
    "href": "plot/1 seaborn.html#color-by-group",
    "title": "seaborn chart",
    "section": "1.1 color by group",
    "text": "1.1 color by group\n\n\nCode\nsns.scatterplot(data=tips,x='tip',y='total_bill',hue='sex')",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#size-by-group",
    "href": "plot/1 seaborn.html#size-by-group",
    "title": "seaborn chart",
    "section": "1.2 size by group",
    "text": "1.2 size by group\n\n\nCode\nsns.scatterplot(data=tips,x='tip',y='total_bill',size='size')",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#color-by-group-1",
    "href": "plot/1 seaborn.html#color-by-group-1",
    "title": "seaborn chart",
    "section": "2.1 color by group",
    "text": "2.1 color by group\n\n\nCode\nsns.lineplot(data=tips,x='tip',y='total_bill',hue='sex')",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#color-by-group-2",
    "href": "plot/1 seaborn.html#color-by-group-2",
    "title": "seaborn chart",
    "section": "3.1 color by group",
    "text": "3.1 color by group\n\n\nCode\nsns.histplot(data=tips,x='tip',hue='sex',multiple=\"dodge\")",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#color-by-group-3",
    "href": "plot/1 seaborn.html#color-by-group-3",
    "title": "seaborn chart",
    "section": "5.1 color by group",
    "text": "5.1 color by group\n\n\nCode\nsns.boxplot(data=tips,x='day',y='tip',hue='sex')",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "plot/1 seaborn.html#color-by-group-4",
    "href": "plot/1 seaborn.html#color-by-group-4",
    "title": "seaborn chart",
    "section": "6.1 color by group",
    "text": "6.1 color by group\n\n\nCode\nsns.stripplot(data=tips,x='day',y='tip',hue='sex',dodge=True)",
    "crumbs": [
      "Plot",
      "seaborn chart"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html",
    "href": "regression/4 Random forest on house price data.html",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "",
    "text": "with pipeline and tunning",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#input-data",
    "href": "regression/4 Random forest on house price data.html#input-data",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nId = df_train['Id']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\n\n\nCode\n#df_train.info()\n\n\n\n\nCode\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['SalePrice'], axis=1), df_test])",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#data-eda",
    "href": "regression/4 Random forest on house price data.html#data-eda",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\nin step 1",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#data-wrangling",
    "href": "regression/4 Random forest on house price data.html#data-wrangling",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#split-data",
    "href": "regression/4 Random forest on house price data.html#split-data",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY = df_train.SalePrice\nX = df_train.drop(['SalePrice'], axis=1)\n\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nprint(X_train.shape)\nprint(X_test.shape)\n\n\n(1168, 80)\n(292, 80)\n\n\n\n\nCode\nprint(Y_train.shape)\nprint(Y_test.shape)\n\n\n(1168,)\n(292,)\n\n\n\n\nCode\ncategorical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].nunique() &lt; 10 and X_train[cname].dtype == \"object\"]\n                    \n                    \nnumerical_cols = numerical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].dtype in ['int64', 'float64']]\n\n\n\n\nCode\nprint(\"The total number of categorical columns:\", len(categorical_cols))\nprint(\"The total number of numerical columns:\", len(numerical_cols))\n\n\nThe total number of categorical columns: 40\nThe total number of numerical columns: 37\n\n\n\n\nCode\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_test= X_test[my_cols].copy()\n\n\nX_final = df_test[my_cols].copy()",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#pipelines-for-data-preprocessing",
    "href": "regression/4 Random forest on house price data.html#pipelines-for-data-preprocessing",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "2.5 Pipelines for Data Preprocessing",
    "text": "2.5 Pipelines for Data Preprocessing\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nnumerical_transformer = Pipeline(steps=[\n    ('imputer_num', SimpleImputer(strategy='median')), \n    ('scaler', StandardScaler())\n])\n\n\n\n\nCode\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer_cat', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)])",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#define-model",
    "href": "regression/4 Random forest on house price data.html#define-model",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.1 define model",
    "text": "3.1 define model\nrandom forest with hyper parameter tuning\n\n\nCode\nfrom sklearn.ensemble import RandomForestRegressor\n   \n\nml_model = RandomForestRegressor(random_state=0)\nml_model\n\n\nRandomForestRegressor(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriNot fittedRandomForestRegressor(random_state=0)",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#define-pipline",
    "href": "regression/4 Random forest on house price data.html#define-pipline",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.2 define pipline",
    "text": "3.2 define pipline\n\n\nCode\npipeline = Pipeline(\n  steps=[\n         ('preprocessor', preprocessor), \n         ('model', ml_model)\n         ]\n)",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#hyperparameter-tuning-set",
    "href": "regression/4 Random forest on house price data.html#hyperparameter-tuning-set",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.3 hyperparameter tuning set",
    "text": "3.3 hyperparameter tuning set\n\n\nCode\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'model__max_depth':[20,30,40],\n                 'model__n_estimators':[200,250,300],\n                 'model__min_samples_leaf':[1,2,3]\n                 }\n                 \n              \nGridCV = GridSearchCV(pipeline, param_grid, n_jobs= -1, verbose=1)",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#train-model",
    "href": "regression/4 Random forest on house price data.html#train-model",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.4 train model",
    "text": "3.4 train model\n\n\nCode\nGridCV.fit(X_train, Y_train)\n\n\nFitting 5 folds for each of 27 candidates, totalling 135 fits\n\n\nGridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('imputer_num',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('scaler',\n                                                                                          StandardScaler())]),\n                                                                         ['Id',\n                                                                          'MSSubClass',\n                                                                          'LotFrontage',\n                                                                          'LotArea',\n                                                                          'OverallQual',\n                                                                          'OverallCond',\n                                                                          'YearBuilt',\n                                                                          'YearRemodAdd',\n                                                                          'MasVnrArea',\n                                                                          'BsmtFinSF1',\n                                                                          'BsmtFinSF2',\n                                                                          'BsmtUnfSF',\n                                                                          'TotalBsmtSF...\n                                                                          'Foundation',\n                                                                          'BsmtQual',\n                                                                          'BsmtCond',\n                                                                          'BsmtExposure',\n                                                                          'BsmtFinType1',\n                                                                          'BsmtFinType2',\n                                                                          'Heating',\n                                                                          'HeatingQC',\n                                                                          'CentralAir',\n                                                                          'Electrical',\n                                                                          'KitchenQual',\n                                                                          'Functional',\n                                                                          'FireplaceQu', ...])])),\n                                       ('model',\n                                        RandomForestRegressor(random_state=0))]),\n             n_jobs=-1,\n             param_grid={'model__max_depth': [20, 30, 40],\n                         'model__min_samples_leaf': [1, 2, 3],\n                         'model__n_estimators': [200, 250, 300]},\n             verbose=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GridSearchCV?Documentation for GridSearchCViFittedGridSearchCV(estimator=Pipeline(steps=[('preprocessor',\n                                        ColumnTransformer(transformers=[('num',\n                                                                         Pipeline(steps=[('imputer_num',\n                                                                                          SimpleImputer(strategy='median')),\n                                                                                         ('scaler',\n                                                                                          StandardScaler())]),\n                                                                         ['Id',\n                                                                          'MSSubClass',\n                                                                          'LotFrontage',\n                                                                          'LotArea',\n                                                                          'OverallQual',\n                                                                          'OverallCond',\n                                                                          'YearBuilt',\n                                                                          'YearRemodAdd',\n                                                                          'MasVnrArea',\n                                                                          'BsmtFinSF1',\n                                                                          'BsmtFinSF2',\n                                                                          'BsmtUnfSF',\n                                                                          'TotalBsmtSF...\n                                                                          'Foundation',\n                                                                          'BsmtQual',\n                                                                          'BsmtCond',\n                                                                          'BsmtExposure',\n                                                                          'BsmtFinType1',\n                                                                          'BsmtFinType2',\n                                                                          'Heating',\n                                                                          'HeatingQC',\n                                                                          'CentralAir',\n                                                                          'Electrical',\n                                                                          'KitchenQual',\n                                                                          'Functional',\n                                                                          'FireplaceQu', ...])])),\n                                       ('model',\n                                        RandomForestRegressor(random_state=0))]),\n             n_jobs=-1,\n             param_grid={'model__max_depth': [20, 30, 40],\n                         'model__min_samples_leaf': [1, 2, 3],\n                         'model__n_estimators': [200, 250, 300]},\n             verbose=1) estimator: PipelinePipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                                                   'LotConfig', 'LandSlope',\n                                                   'Condition1', 'Condition2',\n                                                   'BldgType', 'HouseStyle',\n                                                   'RoofStyle', 'RoofMatl',\n                                                   'MasVnrType', 'ExterQual',\n                                                   'ExterCond', 'Foundation',\n                                                   'BsmtQual', 'BsmtCond',\n                                                   'BsmtExposure',\n                                                   'BsmtFinType1',\n                                                   'BsmtFinType2', 'Heating',\n                                                   'HeatingQC', 'CentralAir',\n                                                   'Electrical', 'KitchenQual',\n                                                   'Functional', 'FireplaceQu', ...])])),\n                ('model', RandomForestRegressor(random_state=0))])  preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer_num',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 ['Id', 'MSSubClass', 'LotFrontage', 'LotArea',\n                                  'OverallQual', 'OverallCond', 'YearBuilt',\n                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n                                  'GrLivArea', 'Bsm...\n                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n                                  'LandContour', 'Utilities', 'LotConfig',\n                                  'LandSlope', 'Condition1', 'Condition2',\n                                  'BldgType', 'HouseStyle', 'RoofStyle',\n                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n                                  'ExterCond', 'Foundation', 'BsmtQual',\n                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n                                  'CentralAir', 'Electrical', 'KitchenQual',\n                                  'Functional', 'FireplaceQu', ...])]) num['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median')  StandardScaler?Documentation for StandardScalerStandardScaler() cat['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent')  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore')  RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(random_state=0) \n\n\n\n\nCode\nGridCV.best_params_\n\n\n{'model__max_depth': 20,\n 'model__min_samples_leaf': 1,\n 'model__n_estimators': 250}\n\n\n\n\nCode\nGridCV.best_score_\n\n\n0.8460175478594797\n\n\nbest model as pipeline\n\n\nCode\noptimised_model_pipeline = GridCV.best_estimator_\n\n\n\n\nCode\nvar=optimised_model_pipeline[:-1].get_feature_names_out()\n#var\n\n\n\n\nCode\nfitted_model=optimised_model_pipeline.steps[1][1]\n\n\nvariable importance\n\n\nCode\nimportances = fitted_model.feature_importances_\nvi=pd.DataFrame({\"variable\":var,\"importances\":importances})\nvi=vi.sort_values('importances',ascending=False)\nvi\n\n\n\n\n\n\n\n\n\n\nvariable\nimportances\n\n\n\n\n4\nnum__OverallQual\n5.803224e-01\n\n\n16\nnum__GrLivArea\n9.376094e-02\n\n\n12\nnum__TotalBsmtSF\n3.914002e-02\n\n\n14\nnum__2ndFlrSF\n3.678315e-02\n\n\n9\nnum__BsmtFinSF1\n3.388912e-02\n\n\n...\n...\n...\n\n\n210\ncat__MiscFeature_Othr\n1.132910e-07\n\n\n115\ncat__ExterCond_Po\n7.242430e-08\n\n\n77\ncat__Condition2_RRAn\n1.400864e-08\n\n\n101\ncat__RoofMatl_Roll\n4.842303e-09\n\n\n54\ncat__Utilities_AllPub\n0.000000e+00\n\n\n\n\n227 rows × 2 columns",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#preformance",
    "href": "regression/4 Random forest on house price data.html#preformance",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.5 Preformance",
    "text": "3.5 Preformance\n\n\nCode\nY_pred_dt =optimised_model_pipeline.predict(X_test) #always gets x and retuns y\n\n\nR 2\n\n\nCode\nfrom sklearn.metrics import r2_score\nr2_score(Y_test, Y_pred_dt)\n\n\n0.902430134588089\n\n\nMAE\n\n\nCode\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(Y_test, Y_pred_dt)\n\n\n16166.78183388635\n\n\nRMSE\n\n\nCode\nfrom  math import sqrt\nfrom sklearn.metrics import mean_squared_error\nmse=mean_squared_error(Y_test, Y_pred_dt)\nrmse=sqrt(mse)\nrmse\n\n\n23367.187781406363",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/4 Random forest on house price data.html#k-fold-cross-validation",
    "href": "regression/4 Random forest on house price data.html#k-fold-cross-validation",
    "title": "Random forest and pipeline, hyperparameter tuning",
    "section": "3.6 k-Fold Cross-Validation",
    "text": "3.6 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \n\n\n\n\nCode\ncv_dt = cross_val_score(optimised_model_pipeline, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.8315041213032555\n\n\n\n\nCode\ncv_dt = cross_val_score(optimised_model_pipeline, X_train, Y_train, cv=kf_dt,scoring = 'neg_mean_squared_error')\nnp.mean(np.sqrt(np.abs(cv_dt)))\n\n\n32285.99963113304",
    "crumbs": [
      "Regression",
      "Random forest and pipeline, hyperparameter tuning"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html",
    "href": "regression/3 Random forest on house price data.html",
    "title": "Random forest and pipeline",
    "section": "",
    "text": "with pipeline",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#input-data",
    "href": "regression/3 Random forest on house price data.html#input-data",
    "title": "Random forest and pipeline",
    "section": "2.1 input data",
    "text": "2.1 input data\n\n\nCode\n# Loading the data\ndf_train = pd.read_csv('./data/train.csv')\ndf_test = pd.read_csv('./data/test.csv')\n\n# Store our test passenger IDs for easy access\nId = df_train['Id']\n\n\n# Showing overview of the train dataset\ndf_train.head()\n\n\n\n\n\n\n\n\n\n\nId\nMSSubClass\nMSZoning\nLotFrontage\nLotArea\nStreet\nAlley\nLotShape\nLandContour\nUtilities\n...\nPoolArea\nPoolQC\nFence\nMiscFeature\nMiscVal\nMoSold\nYrSold\nSaleType\nSaleCondition\nSalePrice\n\n\n\n\n0\n1\n60\nRL\n65.0\n8450\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2008\nWD\nNormal\n208500\n\n\n1\n2\n20\nRL\n80.0\n9600\nPave\nNaN\nReg\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n5\n2007\nWD\nNormal\n181500\n\n\n2\n3\n60\nRL\n68.0\n11250\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n9\n2008\nWD\nNormal\n223500\n\n\n3\n4\n70\nRL\n60.0\n9550\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n2\n2006\nWD\nAbnorml\n140000\n\n\n4\n5\n60\nRL\n84.0\n14260\nPave\nNaN\nIR1\nLvl\nAllPub\n...\n0\nNaN\nNaN\nNaN\n0\n12\n2008\nWD\nNormal\n250000\n\n\n\n\n5 rows × 81 columns\n\n\n\n\n\n\nCode\n#df_train.info()\n\n\n\n\nCode\ndf_train['role'] = 'train'\ndf_test['role'] = 'test'\n\n# Concatenate training and test sets\ndata = pd.concat([df_train.drop(['SalePrice'], axis=1), df_test])",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#data-eda",
    "href": "regression/3 Random forest on house price data.html#data-eda",
    "title": "Random forest and pipeline",
    "section": "2.2 data EDA",
    "text": "2.2 data EDA\nin step 1",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#data-wrangling",
    "href": "regression/3 Random forest on house price data.html#data-wrangling",
    "title": "Random forest and pipeline",
    "section": "2.3 Data Wrangling",
    "text": "2.3 Data Wrangling",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#split-data",
    "href": "regression/3 Random forest on house price data.html#split-data",
    "title": "Random forest and pipeline",
    "section": "2.4 split data",
    "text": "2.4 split data\n\n\nCode\nY = df_train.SalePrice\nX = df_train.drop(['SalePrice'], axis=1)\n\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(X,Y,train_size = 0.8)\n\nX_train = X_train.drop('role', axis=1)\nX_test = X_test.drop('role', axis=1)\n\n\n\n\nCode\nprint(X_train.shape)\nprint(X_test.shape)\n\n\n(1168, 80)\n(292, 80)\n\n\n\n\nCode\nprint(Y_train.shape)\nprint(Y_test.shape)\n\n\n(1168,)\n(292,)\n\n\n\n\nCode\ncategorical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].nunique() &lt; 10 and X_train[cname].dtype == \"object\"]\n                    \n                    \nnumerical_cols = numerical_cols = [cname for cname in X_train.columns \n                    if X_train[cname].dtype in ['int64', 'float64']]\n\n\n\n\nCode\nprint(\"The total number of categorical columns:\", len(categorical_cols))\nprint(\"The total number of numerical columns:\", len(numerical_cols))\n\n\nThe total number of categorical columns: 40\nThe total number of numerical columns: 37\n\n\n\n\nCode\nmy_cols = categorical_cols + numerical_cols\nX_train = X_train[my_cols].copy()\nX_test= X_test[my_cols].copy()\n\n\nX_final = df_test[my_cols].copy()",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#pipelines-for-data-preprocessing",
    "href": "regression/3 Random forest on house price data.html#pipelines-for-data-preprocessing",
    "title": "Random forest and pipeline",
    "section": "2.5 Pipelines for Data Preprocessing",
    "text": "2.5 Pipelines for Data Preprocessing\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n\n\n\nCode\nnumerical_transformer = Pipeline(steps=[\n    ('imputer_num', SimpleImputer(strategy='median')), \n    ('scaler', StandardScaler())\n])\n\n\n\n\nCode\nfrom sklearn.preprocessing import OneHotEncoder\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer_cat', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n\n\n\nCode\nfrom sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(transformers=[\n    ('num', numerical_transformer, numerical_cols),\n    ('cat', categorical_transformer, categorical_cols)])",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#define-model",
    "href": "regression/3 Random forest on house price data.html#define-model",
    "title": "Random forest and pipeline",
    "section": "3.1 define model",
    "text": "3.1 define model\nrandom forest with hyper parameter tuning\n\n\nCode\nfrom sklearn.ensemble import RandomForestRegressor\n   \n\nml_model = RandomForestRegressor(random_state=0)\nml_model\n\n\nRandomForestRegressor(random_state=0)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriNot fittedRandomForestRegressor(random_state=0)",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#define-pipline",
    "href": "regression/3 Random forest on house price data.html#define-pipline",
    "title": "Random forest and pipeline",
    "section": "3.2 define pipline",
    "text": "3.2 define pipline\n\n\nCode\npipeline = Pipeline(\n  steps=[\n         ('preprocessor', preprocessor), \n         ('model', ml_model)\n         ]\n)",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#train-model",
    "href": "regression/3 Random forest on house price data.html#train-model",
    "title": "Random forest and pipeline",
    "section": "3.3 train model",
    "text": "3.3 train model\n\n\nCode\npipeline.fit(X_train, Y_train)\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                                                   'LotConfig', 'LandSlope',\n                                                   'Condition1', 'Condition2',\n                                                   'BldgType', 'HouseStyle',\n                                                   'RoofStyle', 'RoofMatl',\n                                                   'MasVnrType', 'ExterQual',\n                                                   'ExterCond', 'Foundation',\n                                                   'BsmtQual', 'BsmtCond',\n                                                   'BsmtExposure',\n                                                   'BsmtFinType1',\n                                                   'BsmtFinType2', 'Heating',\n                                                   'HeatingQC', 'CentralAir',\n                                                   'Electrical', 'KitchenQual',\n                                                   'Functional', 'FireplaceQu', ...])])),\n                ('model', RandomForestRegressor(random_state=0))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  Pipeline?Documentation for PipelineiFittedPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('imputer_num',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['Id', 'MSSubClass',\n                                                   'LotFrontage', 'LotArea',\n                                                   'OverallQual', 'OverallCond',\n                                                   'YearBuilt', 'YearRemodAdd',\n                                                   'MasVnrArea', 'BsmtFinSF1',\n                                                   'BsmtFinSF2', 'BsmtUnfSF',\n                                                   'TotalBsmtSF', '1stFlrSF',\n                                                   '2ndFlrSF'...\n                                                   'LotConfig', 'LandSlope',\n                                                   'Condition1', 'Condition2',\n                                                   'BldgType', 'HouseStyle',\n                                                   'RoofStyle', 'RoofMatl',\n                                                   'MasVnrType', 'ExterQual',\n                                                   'ExterCond', 'Foundation',\n                                                   'BsmtQual', 'BsmtCond',\n                                                   'BsmtExposure',\n                                                   'BsmtFinType1',\n                                                   'BsmtFinType2', 'Heating',\n                                                   'HeatingQC', 'CentralAir',\n                                                   'Electrical', 'KitchenQual',\n                                                   'Functional', 'FireplaceQu', ...])])),\n                ('model', RandomForestRegressor(random_state=0))])  preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformerColumnTransformer(transformers=[('num',\n                                 Pipeline(steps=[('imputer_num',\n                                                  SimpleImputer(strategy='median')),\n                                                 ('scaler', StandardScaler())]),\n                                 ['Id', 'MSSubClass', 'LotFrontage', 'LotArea',\n                                  'OverallQual', 'OverallCond', 'YearBuilt',\n                                  'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n                                  'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF',\n                                  '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n                                  'GrLivArea', 'Bsm...\n                                 ['MSZoning', 'Street', 'Alley', 'LotShape',\n                                  'LandContour', 'Utilities', 'LotConfig',\n                                  'LandSlope', 'Condition1', 'Condition2',\n                                  'BldgType', 'HouseStyle', 'RoofStyle',\n                                  'RoofMatl', 'MasVnrType', 'ExterQual',\n                                  'ExterCond', 'Foundation', 'BsmtQual',\n                                  'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n                                  'BsmtFinType2', 'Heating', 'HeatingQC',\n                                  'CentralAir', 'Electrical', 'KitchenQual',\n                                  'Functional', 'FireplaceQu', ...])]) num['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='median')  StandardScaler?Documentation for StandardScalerStandardScaler() cat['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']  SimpleImputer?Documentation for SimpleImputerSimpleImputer(strategy='most_frequent')  OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(handle_unknown='ignore')  RandomForestRegressor?Documentation for RandomForestRegressorRandomForestRegressor(random_state=0) \n\n\n\n\nCode\nvar=pipeline[:-1].get_feature_names_out()\nvar\n\n\narray(['num__Id', 'num__MSSubClass', 'num__LotFrontage', 'num__LotArea',\n       'num__OverallQual', 'num__OverallCond', 'num__YearBuilt',\n       'num__YearRemodAdd', 'num__MasVnrArea', 'num__BsmtFinSF1',\n       'num__BsmtFinSF2', 'num__BsmtUnfSF', 'num__TotalBsmtSF',\n       'num__1stFlrSF', 'num__2ndFlrSF', 'num__LowQualFinSF',\n       'num__GrLivArea', 'num__BsmtFullBath', 'num__BsmtHalfBath',\n       'num__FullBath', 'num__HalfBath', 'num__BedroomAbvGr',\n       'num__KitchenAbvGr', 'num__TotRmsAbvGrd', 'num__Fireplaces',\n       'num__GarageYrBlt', 'num__GarageCars', 'num__GarageArea',\n       'num__WoodDeckSF', 'num__OpenPorchSF', 'num__EnclosedPorch',\n       'num__3SsnPorch', 'num__ScreenPorch', 'num__PoolArea',\n       'num__MiscVal', 'num__MoSold', 'num__YrSold',\n       'cat__MSZoning_C (all)', 'cat__MSZoning_FV', 'cat__MSZoning_RH',\n       'cat__MSZoning_RL', 'cat__MSZoning_RM', 'cat__Street_Grvl',\n       'cat__Street_Pave', 'cat__Alley_Grvl', 'cat__Alley_Pave',\n       'cat__LotShape_IR1', 'cat__LotShape_IR2', 'cat__LotShape_IR3',\n       'cat__LotShape_Reg', 'cat__LandContour_Bnk',\n       'cat__LandContour_HLS', 'cat__LandContour_Low',\n       'cat__LandContour_Lvl', 'cat__Utilities_AllPub',\n       'cat__Utilities_NoSeWa', 'cat__LotConfig_Corner',\n       'cat__LotConfig_CulDSac', 'cat__LotConfig_FR2',\n       'cat__LotConfig_FR3', 'cat__LotConfig_Inside',\n       'cat__LandSlope_Gtl', 'cat__LandSlope_Mod', 'cat__LandSlope_Sev',\n       'cat__Condition1_Artery', 'cat__Condition1_Feedr',\n       'cat__Condition1_Norm', 'cat__Condition1_PosA',\n       'cat__Condition1_PosN', 'cat__Condition1_RRAe',\n       'cat__Condition1_RRAn', 'cat__Condition1_RRNe',\n       'cat__Condition1_RRNn', 'cat__Condition2_Artery',\n       'cat__Condition2_Feedr', 'cat__Condition2_Norm',\n       'cat__Condition2_PosA', 'cat__Condition2_PosN',\n       'cat__Condition2_RRAe', 'cat__Condition2_RRAn',\n       'cat__Condition2_RRNn', 'cat__BldgType_1Fam',\n       'cat__BldgType_2fmCon', 'cat__BldgType_Duplex',\n       'cat__BldgType_Twnhs', 'cat__BldgType_TwnhsE',\n       'cat__HouseStyle_1.5Fin', 'cat__HouseStyle_1.5Unf',\n       'cat__HouseStyle_1Story', 'cat__HouseStyle_2.5Fin',\n       'cat__HouseStyle_2.5Unf', 'cat__HouseStyle_2Story',\n       'cat__HouseStyle_SFoyer', 'cat__HouseStyle_SLvl',\n       'cat__RoofStyle_Flat', 'cat__RoofStyle_Gable',\n       'cat__RoofStyle_Gambrel', 'cat__RoofStyle_Hip',\n       'cat__RoofStyle_Mansard', 'cat__RoofStyle_Shed',\n       'cat__RoofMatl_ClyTile', 'cat__RoofMatl_CompShg',\n       'cat__RoofMatl_Membran', 'cat__RoofMatl_Metal',\n       'cat__RoofMatl_Roll', 'cat__RoofMatl_Tar&Grv',\n       'cat__RoofMatl_WdShake', 'cat__RoofMatl_WdShngl',\n       'cat__MasVnrType_BrkCmn', 'cat__MasVnrType_BrkFace',\n       'cat__MasVnrType_Stone', 'cat__ExterQual_Ex', 'cat__ExterQual_Fa',\n       'cat__ExterQual_Gd', 'cat__ExterQual_TA', 'cat__ExterCond_Ex',\n       'cat__ExterCond_Fa', 'cat__ExterCond_Gd', 'cat__ExterCond_Po',\n       'cat__ExterCond_TA', 'cat__Foundation_BrkTil',\n       'cat__Foundation_CBlock', 'cat__Foundation_PConc',\n       'cat__Foundation_Slab', 'cat__Foundation_Stone',\n       'cat__Foundation_Wood', 'cat__BsmtQual_Ex', 'cat__BsmtQual_Fa',\n       'cat__BsmtQual_Gd', 'cat__BsmtQual_TA', 'cat__BsmtCond_Fa',\n       'cat__BsmtCond_Gd', 'cat__BsmtCond_Po', 'cat__BsmtCond_TA',\n       'cat__BsmtExposure_Av', 'cat__BsmtExposure_Gd',\n       'cat__BsmtExposure_Mn', 'cat__BsmtExposure_No',\n       'cat__BsmtFinType1_ALQ', 'cat__BsmtFinType1_BLQ',\n       'cat__BsmtFinType1_GLQ', 'cat__BsmtFinType1_LwQ',\n       'cat__BsmtFinType1_Rec', 'cat__BsmtFinType1_Unf',\n       'cat__BsmtFinType2_ALQ', 'cat__BsmtFinType2_BLQ',\n       'cat__BsmtFinType2_GLQ', 'cat__BsmtFinType2_LwQ',\n       'cat__BsmtFinType2_Rec', 'cat__BsmtFinType2_Unf',\n       'cat__Heating_Floor', 'cat__Heating_GasA', 'cat__Heating_GasW',\n       'cat__Heating_Grav', 'cat__Heating_OthW', 'cat__Heating_Wall',\n       'cat__HeatingQC_Ex', 'cat__HeatingQC_Fa', 'cat__HeatingQC_Gd',\n       'cat__HeatingQC_Po', 'cat__HeatingQC_TA', 'cat__CentralAir_N',\n       'cat__CentralAir_Y', 'cat__Electrical_FuseA',\n       'cat__Electrical_FuseF', 'cat__Electrical_FuseP',\n       'cat__Electrical_Mix', 'cat__Electrical_SBrkr',\n       'cat__KitchenQual_Ex', 'cat__KitchenQual_Fa',\n       'cat__KitchenQual_Gd', 'cat__KitchenQual_TA',\n       'cat__Functional_Maj1', 'cat__Functional_Maj2',\n       'cat__Functional_Min1', 'cat__Functional_Min2',\n       'cat__Functional_Mod', 'cat__Functional_Sev',\n       'cat__Functional_Typ', 'cat__FireplaceQu_Ex',\n       'cat__FireplaceQu_Fa', 'cat__FireplaceQu_Gd',\n       'cat__FireplaceQu_Po', 'cat__FireplaceQu_TA',\n       'cat__GarageType_2Types', 'cat__GarageType_Attchd',\n       'cat__GarageType_Basment', 'cat__GarageType_BuiltIn',\n       'cat__GarageType_CarPort', 'cat__GarageType_Detchd',\n       'cat__GarageFinish_Fin', 'cat__GarageFinish_RFn',\n       'cat__GarageFinish_Unf', 'cat__GarageQual_Ex',\n       'cat__GarageQual_Fa', 'cat__GarageQual_Gd', 'cat__GarageQual_Po',\n       'cat__GarageQual_TA', 'cat__GarageCond_Ex', 'cat__GarageCond_Fa',\n       'cat__GarageCond_Gd', 'cat__GarageCond_Po', 'cat__GarageCond_TA',\n       'cat__PavedDrive_N', 'cat__PavedDrive_P', 'cat__PavedDrive_Y',\n       'cat__PoolQC_Ex', 'cat__PoolQC_Fa', 'cat__PoolQC_Gd',\n       'cat__Fence_GdPrv', 'cat__Fence_GdWo', 'cat__Fence_MnPrv',\n       'cat__Fence_MnWw', 'cat__MiscFeature_Gar2',\n       'cat__MiscFeature_Othr', 'cat__MiscFeature_Shed',\n       'cat__MiscFeature_TenC', 'cat__SaleType_COD', 'cat__SaleType_CWD',\n       'cat__SaleType_Con', 'cat__SaleType_ConLD', 'cat__SaleType_ConLI',\n       'cat__SaleType_ConLw', 'cat__SaleType_New', 'cat__SaleType_Oth',\n       'cat__SaleType_WD', 'cat__SaleCondition_Abnorml',\n       'cat__SaleCondition_AdjLand', 'cat__SaleCondition_Alloca',\n       'cat__SaleCondition_Family', 'cat__SaleCondition_Normal',\n       'cat__SaleCondition_Partial'], dtype=object)\n\n\n\n\nCode\nfitted_model=pipeline.steps[1][1]\n\n\nvariable importance\n\n\nCode\nimportances = fitted_model.feature_importances_\nvi=pd.DataFrame({\"variable\":var,\"importances\":importances})\nvi=vi.sort_values('importances',ascending=False)\nvi\n\n\n\n\n\n\n\n\n\n\nvariable\nimportances\n\n\n\n\n4\nnum__OverallQual\n6.020234e-01\n\n\n16\nnum__GrLivArea\n1.184263e-01\n\n\n12\nnum__TotalBsmtSF\n3.276525e-02\n\n\n9\nnum__BsmtFinSF1\n2.627399e-02\n\n\n26\nnum__GarageCars\n2.277061e-02\n\n\n...\n...\n...\n\n\n79\ncat__Condition2_RRAn\n3.114047e-08\n\n\n165\ncat__Electrical_FuseP\n2.017559e-09\n\n\n104\ncat__RoofMatl_Roll\n0.000000e+00\n\n\n99\ncat__RoofStyle_Shed\n0.000000e+00\n\n\n76\ncat__Condition2_PosA\n0.000000e+00\n\n\n\n\n232 rows × 2 columns",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#preformance",
    "href": "regression/3 Random forest on house price data.html#preformance",
    "title": "Random forest and pipeline",
    "section": "3.4 Preformance",
    "text": "3.4 Preformance\n\n\nCode\nY_pred_dt =pipeline.predict(X_test) #always gets x and retuns y\n\n\nR 2\n\n\nCode\nfrom sklearn.metrics import r2_score\nr2_score(Y_test, Y_pred_dt)\n\n\n0.8738373220842524\n\n\nMAE\n\n\nCode\nfrom sklearn.metrics import mean_absolute_error\nmean_absolute_error(Y_test, Y_pred_dt)\n\n\n16591.730136986298\n\n\nRMSE\n\n\nCode\nfrom  math import sqrt\nfrom sklearn.metrics import mean_squared_error\nmse=mean_squared_error(Y_test, Y_pred_dt)\nrmse=sqrt(mse)\nrmse\n\n\n27704.74856770407",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "regression/3 Random forest on house price data.html#k-fold-cross-validation",
    "href": "regression/3 Random forest on house price data.html#k-fold-cross-validation",
    "title": "Random forest and pipeline",
    "section": "3.5 k-Fold Cross-Validation",
    "text": "3.5 k-Fold Cross-Validation\n\n\nCode\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\n\n\n\n\nCode\nkf_dt = KFold(n_splits=5,shuffle=True)  \n\n\n\n\nCode\ncv_dt = cross_val_score(pipeline, X_train, Y_train, cv=kf_dt)\nnp.mean(cv_dt)\n\n\n0.8442740125584562\n\n\n\n\nCode\ncv_dt = cross_val_score(pipeline, X_train, Y_train, cv=kf_dt,scoring = 'neg_mean_squared_error')\nnp.mean(np.sqrt(np.abs(cv_dt)))\n\n\n30836.193801751524",
    "crumbs": [
      "Regression",
      "Random forest and pipeline"
    ]
  },
  {
    "objectID": "model type/1 decision tree.html",
    "href": "model type/1 decision tree.html",
    "title": "Decision tree",
    "section": "",
    "text": "1 Pros\n\nEasier to interpret than Neural Network\nFast training and making inference\n\n\n\n2 Cons\n\nProne to overfitting\n\n\n\n3 reference:\nhttps://www.youtube.com/watch?v=6DlWndLbk90",
    "crumbs": [
      "model type",
      "Decision tree"
    ]
  },
  {
    "objectID": "data/2 siuba.html",
    "href": "data/2 siuba.html",
    "title": "Data manipulation with siuba",
    "section": "",
    "text": "1 reference:\nhttps://siuba.org/",
    "crumbs": [
      "Data",
      "Data manipulation with siuba"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\nhttps://tonyfly3000.github.io/scikit-learn-in-Python/\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "intro/4 data structure in Python .html#singular",
    "href": "intro/4 data structure in Python .html#singular",
    "title": "data structure in Python",
    "section": "1.1 singular",
    "text": "1.1 singular\n\n\nCode\na=1\ntype(a)\n\n\nint\n\n\n\n\nCode\na=1.3\ntype(a)\n\n\nfloat\n\n\n\n\nCode\na='hell'\ntype(a)\n\n\nstr",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#list",
    "href": "intro/4 data structure in Python .html#list",
    "title": "data structure in Python",
    "section": "1.2 list",
    "text": "1.2 list\n\n\nCode\na=[1,2,3]\n\na\n\n\n[1, 2, 3]\n\n\n\n\nCode\ntype(a) \n\n\nlist\n\n\n\n\nCode\nfruits = ['orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana','apple']\n\n\n\n1.2.1 find length of the list with len()\n\n\nCode\nlen(fruits)\n\n\n8\n\n\n\n\n1.2.2 find how many time in the list with count()\n\n\nCode\nfruits.count('apple')\n\n\n3\n\n\n\n\n1.2.3 find locaiton of on the list with index()\nshow the first ‘apple’ index. python list start at 0\n\n\nCode\nfruits.index('apple')\n\n\n1\n\n\nall ‘apple’ in the list\n\n\nCode\n[index for index, value in enumerate(fruits) if value == 'apple']\n\n\n[1, 5, 7]",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#reverse-the-list",
    "href": "intro/4 data structure in Python .html#reverse-the-list",
    "title": "data structure in Python",
    "section": "1.3 reverse the list",
    "text": "1.3 reverse the list\n\n\nCode\nfruits.reverse()\nfruits\n\n\n['apple', 'banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange']\n\n\n\n1.3.1 sort the list\n\n\nCode\nfruits.sort()\nfruits\n\n\n['apple', 'apple', 'apple', 'banana', 'banana', 'kiwi', 'orange', 'pear']\n\n\n\n\n1.3.2 add element on the list\n\n\nCode\nfruits.append('grape')\nfruits\n\n\n['apple',\n 'apple',\n 'apple',\n 'banana',\n 'banana',\n 'kiwi',\n 'orange',\n 'pear',\n 'grape']",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#drop-last-element",
    "href": "intro/4 data structure in Python .html#drop-last-element",
    "title": "data structure in Python",
    "section": "1.4 drop last element",
    "text": "1.4 drop last element\n\n\nCode\nfruits.pop()\n\nfruits\n\n\n['apple', 'apple', 'apple', 'banana', 'banana', 'kiwi', 'orange', 'pear']\n\n\n\n1.4.1 List Comprehensions\nusing loop:\n\n\nCode\nsquares = []\nfor x in range(10):\n  squares.append(x**2)\n  \nsquares\n\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\n\nusing List Comprehensions\n\n\nCode\nsquares = [x**2 for x in range(10)]\nsquares\n\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#tuples",
    "href": "intro/4 data structure in Python .html#tuples",
    "title": "data structure in Python",
    "section": "1.5 Tuples",
    "text": "1.5 Tuples\n\n\nCode\nfruits = ('orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana','apple')\n\nfruits\n\n\n('orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana', 'apple')\n\n\n\n\nCode\ntype(fruits)\n\n\ntuple\n\n\ntuple can not be modified.",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#sets",
    "href": "intro/4 data structure in Python .html#sets",
    "title": "data structure in Python",
    "section": "1.6 Sets",
    "text": "1.6 Sets\nA set is an unordered collection with no duplicate elements.\n\n\nCode\nbasket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n\nbasket\n\n\n{'apple', 'banana', 'orange', 'pear'}\n\n\n\n\nCode\ntype(basket)\n\n\nset",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/4 data structure in Python .html#dictionaries",
    "href": "intro/4 data structure in Python .html#dictionaries",
    "title": "data structure in Python",
    "section": "1.7 Dictionaries",
    "text": "1.7 Dictionaries\n\n\nCode\ntel = {'jack': 4098, 'sape': 4139}\n\ntel\n\n\n{'jack': 4098, 'sape': 4139}\n\n\n\n\nCode\ntype(tel)\n\n\ndict\n\n\n\n\nCode\ntel['jack']\n\n\n4098",
    "crumbs": [
      "Intro",
      "data structure in Python"
    ]
  },
  {
    "objectID": "intro/3 install package.html",
    "href": "intro/3 install package.html",
    "title": "install pacakge",
    "section": "",
    "text": "1 package\n\n\nCode\nimport os\nos.system('pip install -U scikit-learn')\n\n\n\n\n2 package version\n\n\nCode\nimport sklearn\nsklearn.show_versions()\n\n\n\nSystem:\n    python: 3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]\nexecutable: /Library/Frameworks/Python.framework/Versions/3.11/bin/python3\n   machine: macOS-14.1.1-arm64-arm-64bit\n\nPython dependencies:\n      sklearn: 1.4.1.post1\n          pip: 24.0\n   setuptools: 65.5.0\n        numpy: 1.26.4\n        scipy: 1.12.0\n       Cython: None\n       pandas: 2.2.1\n   matplotlib: 3.8.3\n       joblib: 1.3.2\nthreadpoolctl: 3.2.0\n\nBuilt with OpenMP: True\n\nthreadpoolctl info:\n       user_api: blas\n   internal_api: openblas\n    num_threads: 8\n         prefix: libopenblas\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/.dylibs/libopenblas64_.0.dylib\n        version: 0.3.23.dev\nthreading_layer: pthreads\n   architecture: armv8\n\n       user_api: openmp\n   internal_api: openmp\n    num_threads: 8\n         prefix: libomp\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/.dylibs/libomp.dylib\n        version: None\n\n       user_api: blas\n   internal_api: openblas\n    num_threads: 8\n         prefix: libopenblas\n       filepath: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/.dylibs/libopenblas.0.dylib\n        version: 0.3.21.dev\nthreading_layer: pthreads\n   architecture: armv8",
    "crumbs": [
      "Intro",
      "install pacakge"
    ]
  }
]