---
title: "Data manipulation with Pandas"
author: "Tony Duan"

execute:
  warning: false
  error: false
format:
  html:
    toc: true
    toc-location: right
    code-fold: show
    code-tools: true
    number-sections: true
    code-block-bg: true
    code-block-border-left: "#31BAE9"
---

![](images/Pandas_logo.svg.png){width="600"}


pandas is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool,
built on top of the Python programming language.


```{python}

import pandas as pd
print('pandas version', pd.__version__)
```

```{python}
import os
#os.system('pip show pandas')
```



## load package
```{python}
import pandas as pd
import numpy as np
import matplotlib.pylab as plt
import seaborn as sns

from siuba.data import mtcars,penguins

from siuba.siu import call
from siuba import _, mutate, filter, group_by, summarize,show_query
from siuba import *

from siuba.data import mtcars,penguins
```





```{python}
small_mtcars = mtcars[["cyl", "mpg",'hp']]
small_mtcars=small_mtcars.head(5)
```

## select column

### get column names

```{python}
list(small_mtcars)
```

### select by name

```{python}
small_mtcars [["cyl", "mpg",'hp']]
```
other way:
```{python}
small_mtcars.filter(items=['cyl', 'mpg','hp'])
```


### select columns by name match with 'p'

```{python}
small_mtcars.loc[:,small_mtcars.columns.str.contains("p")]
```

other way:
```{python}
small_mtcars.filter(regex='p.*', axis=1)
```


### select columns by index

#### select first and 3rd columns
```{python}
small_mtcars.iloc[[0,2]]
```


#### select first to 3rd columns

```{python}
small_mtcars[0:3]
```

## drop column

```{python}
small_mtcars.drop('cyl', axis=1)
```

## Renaming column

```{python}
small_mtcars.rename(columns={'mpg':"new_name_mpg", 'cyl':'new_name_cyl'})
```

## Create column

### Mutate
```{python}

small_mtcars['mpg2'] = small_mtcars['mpg']+1


small_mtcars['mpg3']  = np.where(small_mtcars['mpg']> 20, "long", "short")


small_mtcars['mpg4'] =np.where(small_mtcars["mpg"]<19, "short",
                   np.where(small_mtcars["mpg"]<=22, "Medium",
                   np.where(small_mtcars["mpg"]>22, "long","else")))


small_mtcars
```

### Transmute,create column and only keep this column

```{python}
small_mtcars['mpg2'] = small_mtcars['mpg']+1

new_data=small_mtcars[['mpg2']]

new_data
```




## Filter rows

```{python}
mtcars[(mtcars['gear'] ==4)]
```
other way:
```{python}
mtcars.query('gear==4')
```

### Filters with AND conditions

```{python}

mtcars[(mtcars['cyl'] >4)&(mtcars['gear'] ==5) ]

```
other way:
```{python}
mtcars.query('cyl>4 and gear==5')
```

### Filters with OR conditions


```{python}
mtcars[(mtcars['cyl'] ==6) |(mtcars['gear'] ==5) ]
```

other way:
```{python}
mtcars.query('cyl==6 or gear==5')
```


### filter row with index

#### 5th rows
```{python}
# not in siuba, in pandas
mtcars.iloc[[4]]
```

#### 1 and 5tj rows
```{python}
# not in siuba, in pandas
mtcars.iloc[[0,4]]
```

#### 1 to 5th rows
```{python}
# not in siuba, in pandas
mtcars.iloc[0:4]
```
#### get ramdon 5 rows

```{python}
mtcars.sample(5, random_state=42)
```


## Append


### append by row

```{python}
# not available in siuba yet
#from siuba import bind_rows
```

```{python}
# using pandas

# get 1 to 4 rows
data1=mtcars.iloc[0:4]

# get 9 rows
data2=mtcars.iloc[10:11]

data3=pd.concat([data1, data2], ignore_index = True,axis=0)

data3
```


### append by column

```{python}
# not available in siuba yet
#from siuba import bind_columns
```

```{python}
# using pandas
data1=small_mtcars>>select(_.mpg)

data2=small_mtcars>>select(_.cyl)

data3=pd.concat([data1, data2],axis=1)

data3
```


### Dropping NA values


### keep NA values



## group by

### average,min,max,sum

```{python}
mtcars.groupby("cyl")["hp"].mean()
```
```{python}
mtcars.groupby("cyl")["hp"].min()
```

```{python}
mtcars.groupby("cyl")["hp"].max()
```


```{python}
mtcars.groupby("cyl")["hp"].sum()
```
### count

```{python}

mtcars.groupby("cyl")["cyl"].count()

```


## order rows

```{python}
small_mtcars.sort_values('hp')
```

### Sort in descending order

```{python}
small_mtcars.sort_values('hp',ascending=False)
```

### Arrange by multiple variables


```{python}
small_mtcars.sort_values(by=['cyl','mpg'])
```
## join

```{python}

lhs = pd.DataFrame({'id': [1,2,3], 'val': ['lhs.1', 'lhs.2', 'lhs.3']})
rhs = pd.DataFrame({'id': [1,2,4], 'val': ['rhs.1', 'rhs.2', 'rhs.3']})
```


```{python}
lhs
```

```{python}
rhs
```


### inner_join

```{python}
result=pd.merge(lhs, rhs, on='id', how='inner')
result
```


### full join

```{python}
result=pd.merge(lhs, rhs, on='id', how='outer')
result
```



### left join 

```{python}
result=pd.merge(lhs, rhs, on='id', how='left')
result
```


### anti join

keep data in left which not in right
```{python}
#in siuba
result=lhs >> anti_join(_, rhs, on="id")
result
```


keep data in right which not in left
```{python}
#in siuba
result=rhs >> anti_join(_, lhs, on="id")
result
```


## Reshape tables


```{python}
costs = pd.DataFrame({
    'id': [1,2],
    'price_x': [.1, .2],
    'price_y': [.4, .5],
    'price_z': [.7, .8]
})

costs
```


### Gather data long(wide to long)

```{python}
# selecting each variable manually
long_date=pd.melt(costs,id_vars=['id'], value_vars=['price_x', 'price_y','price_z'])

long_date
#costs >> gather('measure', 'value', _.price_x, _.price_y, _.price_z)
```


### Spread data wide (long to wide)


```{python}
long_date.pivot(index="id", columns="variable", values="value")
```




## string

```{python}

df = pd.DataFrame({'text': ['abc', 'DDD','1243c','aeEe'], 'num': [3, 4,7,8]})

df
```

### upper case

```{python}
df>> mutate(text_new=_.text.str.upper())
```
### lower case

```{python}
df>> mutate(text_new=_.text.str.lower())
```
### match

```{python}
df>> mutate(text_new1=if_else(_.text== "abc",'T','F')
            ,text_new2=if_else(_.text.str.startswith("a"),'T','F')
            ,text_new3=if_else(_.text.str.endswith("c"),'T','F')
            ,text_new4=if_else(_.text.str.contains("4"),'T','F')

)

```

###  concatenation

```{python}
df>> mutate(text_new1=_.text+' is '+_.text
)

```


### replace

Use .str.replace(..., regex=True) with regular expressions to replace patterns in strings.

For example, the code below uses "p.", where . is called a wildcard–which matches any character.

```{python}
df>> mutate(text_new1=_.text.str.replace("a.", "XX", regex=True)
)

```
### extract

Use str.extract() with a regular expression to pull out a matching piece of text.

For example the regular expression “^(.*) ” contains the following pieces:

-  a matches the literal letter “a”

- .* has a . which matches anything, and * which modifies it to apply 0 or more times.

```{python}
df>> mutate(text_new1=_.text.str.extract("a(.*)")
            ,text_new2=_.text.str.extract("(.*)c")
)

```




## date

```{python}
df_dates = pd.DataFrame({
    "dates": pd.to_datetime(["2021-01-02", "2021-02-03"]),
    "raw": ["2023-04-05 06:07:08", "2024-05-06 07:08:09"],
})
df_dates
```


```{python}
from datetime import datetime

df_date=df_dates>>mutate(month=_.dates.dt.month_name()
                  ,date_format_raw = call(pd.to_datetime, _.raw)
                  ,date_format_raw_year=_.date_format_raw.dt.year

)

df_date
```


```{python}
df_date.info()
```



## dataframe to numpy array

```{python}
df_date.to_numpy()
```




# Reference:

https://pandas.pydata.org/docs/user_guide




```{python}
#| eval: false
#| include: false

this is hidding code chunk
```

