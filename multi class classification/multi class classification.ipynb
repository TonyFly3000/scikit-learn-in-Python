{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Multi Models using downsample,pipeline,fast tuning\"\n",
        "subtitle: \"with hotel booking imbalanced data\"\n",
        "execute:\n",
        "  warning: false\n",
        "  error: false\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-location: right\n",
        "    code-fold: show\n",
        "    code-tools: true\n",
        "    number-sections: true\n",
        "    code-block-bg: true\n",
        "    code-block-border-left: \"#31BAE9\"\n",
        "---"
      ],
      "id": "d2467f81"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since we have enough rare class data(at least 1K).Let handle imbalanced data with down sample before training.\n",
        "\n",
        "\n",
        "# load package\n"
      ],
      "id": "fe7843ad"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "from siuba.siu import call\n",
        "from siuba import _, mutate, filter, group_by, summarize,show_query\n",
        "\n",
        "import time\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        "from sklearn.model_selection import HalvingGridSearchCV"
      ],
      "id": "2b754b25",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# data\n",
        "\n",
        "## download data\n",
        "\n",
        "https://www.kaggle.com/datasets/vetrirah/customer\n"
      ],
      "id": "37805451"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_tran_raw=pd.read_csv('data/Train.csv')\n",
        "\n",
        "df_test_raw=pd.read_csv('data/Test.csv')"
      ],
      "id": "3932a661",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## data EDA\n",
        "\n",
        "\n",
        "\n",
        "## Data Wrangling\n"
      ],
      "id": "54d37ae1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_tran_raw.head()"
      ],
      "id": "185dcfaf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_train=df_tran_raw.drop('ID', axis=1)"
      ],
      "id": "7f2740ce",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_test=df_test_raw.drop('ID', axis=1)"
      ],
      "id": "287114e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_train.head()"
      ],
      "id": "def6b6d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_train >> group_by(_.Segmentation)  >> summarize(n = _.shape[0])"
      ],
      "id": "fef29a52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## split data\n",
        "\n",
        "80% training / 10% validation/ 10% testing\n",
        "\n",
        "![](images/1_Nv2NNALuokZEcV6hYEHdGA.webp){width=\"520\"}\n"
      ],
      "id": "053c30bb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Y=df_train['Segmentation']\n",
        "X=df_train.drop('Segmentation', axis=1)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "id": "7cce83dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "collections.Counter(Y)"
      ],
      "id": "775547b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "inverse_transform for testing only\n"
      ],
      "id": "c7fcb901"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "inv = le.inverse_transform(Y)"
      ],
      "id": "91cc342a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "collections.Counter(inv)"
      ],
      "id": "01b25db5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "training_size=0.8\n",
        "validation_size=0.1\n",
        "testing_size=0.1\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val= train_test_split(X, Y, test_size=validation_size, random_state=1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X_train, Y_train, test_size=testing_size/training_size, random_state=1) "
      ],
      "id": "ff0aa9e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_train.shape"
      ],
      "id": "a12227db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Y_train.shape"
      ],
      "id": "54403b84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(X_train)/(len(X_train) +len(X_val) +len(X_test) )"
      ],
      "id": "14338c84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(X_val)/(len(X_train) +len(X_val) +len(X_test) )"
      ],
      "id": "af264c4e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "len(X_test)/(len(X_train) +len(X_val) +len(X_test) )"
      ],
      "id": "9e5cbb0e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## categorical_cols and numerical_cols\n"
      ],
      "id": "b828a4a9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "categorical_cols = [cname for cname in X_train \n",
        "                    if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"]\n",
        "                    \n",
        "                    \n",
        "numerical_cols = numerical_cols = [cname for cname in X_train \n",
        "                    if X_train[cname].dtype in ['int64', 'float64']]"
      ],
      "id": "f0885966",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"The total number of categorical columns:\", len(categorical_cols))\n",
        "print(\"The total number of numerical columns:\", len(numerical_cols))"
      ],
      "id": "717ec4d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train[my_cols].copy()\n",
        "X_val = X_val[my_cols].copy()\n",
        "X_test= X_test[my_cols].copy()\n",
        "\n",
        "my_cols\n",
        "#X_final = df_test[my_cols].copy()"
      ],
      "id": "03b1c6ed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipelines for Data Preprocessing\n"
      ],
      "id": "59646f37"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "id": "c7a6151a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### numerical_transformer\n"
      ],
      "id": "7c897ba2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer_num', SimpleImputer(strategy='median')), \n",
        "    ('scaler', StandardScaler())\n",
        "])"
      ],
      "id": "12a8b5f1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### categorical_transformer\n"
      ],
      "id": "96aa2b73"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer_cat', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])"
      ],
      "id": "3da1022c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numerical_transformer, numerical_cols),\n",
        "    ('cat', categorical_transformer, categorical_cols)])"
      ],
      "id": "c1f87f70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# model\n",
        "\n",
        "\n",
        "## define model\n",
        "\n",
        "\n",
        "### XGB model\n"
      ],
      "id": "cb46565e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import xgboost\n",
        "print(xgboost.__version__)"
      ],
      "id": "2f6fc536",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since its multi calss classification so add `objective='multi:softmax'`"
      ],
      "id": "6f8d98bb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb_model = XGBClassifier(objective='multi:softprob',num_class=4)\n",
        "xgb_model"
      ],
      "id": "6599519e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest model"
      ],
      "id": "e5eebd02"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest_model = RandomForestClassifier()\n",
        "random_forest_model"
      ],
      "id": "154f077f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Logistic Regression model\n"
      ],
      "id": "581b86ff"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LogisticRegression_model = LogisticRegression(solver='liblinear')\n",
        "LogisticRegression_model"
      ],
      "id": "9708df65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## define pipline\n"
      ],
      "id": "2ff1fc4e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pipeline_xgb = Pipeline(\n",
        "  steps=[\n",
        "         ('preprocessor', preprocessor), \n",
        "         ('model', xgb_model)\n",
        "         ]\n",
        ")\n",
        "\n",
        "pipeline_rf = Pipeline(\n",
        "  steps=[\n",
        "         ('preprocessor', preprocessor), \n",
        "         ('model', random_forest_model)\n",
        "         ]\n",
        ")\n",
        "\n",
        "pipeline_lr = Pipeline(\n",
        "  steps=[\n",
        "         ('preprocessor', preprocessor), \n",
        "         ('model', LogisticRegression_model)\n",
        "         ]\n",
        ")"
      ],
      "id": "7e77b326",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## define GridSearch\n"
      ],
      "id": "3236a9e4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parameters_xgb= {\n",
        "        'model__learning_rate': [0.01, 0.02,0.08,0.1],\n",
        "        'model__max_depth': [3, 5, 7,8,9,10],\n",
        "        'model__min_child_weight': [1, 3,5,8],\n",
        "        'model__subsample': [0.5, 0.7,0.9],\n",
        "        \n",
        "       # 'model__colsample__bytree': [0.5, 0.7],\n",
        "       \n",
        "        'model__n_estimators' : [100, 200],\n",
        "        'model__objective': ['reg:squarederror']\n",
        "    }\n",
        "\n",
        "\n",
        "Grid_xgb = HalvingGridSearchCV(pipeline_xgb\n",
        "                ,parameters_xgb \n",
        "                #,scoring='merror'\n",
        "                ,max_resources=100\n",
        "                , cv=10, n_jobs=-1)\n",
        "                \n",
        "                \n",
        "parameters_rf = {'model__max_depth':[20,30,40],\n",
        "                 'model__n_estimators':[200,250],\n",
        "                 'model__min_samples_leaf':[1,2,3]\n",
        "                 }                \n",
        "                \n",
        "\n",
        "Grid_rf = HalvingGridSearchCV(pipeline_rf\n",
        "                ,parameters_rf\n",
        "                #,scoring='merror'\n",
        "                ,max_resources=100\n",
        "                , cv=10, n_jobs=-1)\n"
      ],
      "id": "a37e6be5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## train model\n"
      ],
      "id": "d6051a2d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "start_time = time.time()\n",
        "\n",
        "\n",
        "Grids = [Grid_xgb, Grid_rf,pipeline_xgb,pipeline_rf,pipeline_lr]\n",
        "\n",
        "\n",
        "\n",
        "for Grid in Grids:\n",
        "    Grid.fit(X_train,Y_train)\n",
        "\n",
        "\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "duration\n",
        "\n",
        "print(\"trainning time:\",duration)"
      ],
      "id": "8871473d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preformance\n",
        "\n",
        "### dummy Preformance\n",
        "\n",
        "#### dummy 1 : there are 3 class, so each class random 33.33%"
      ],
      "id": "32fb58ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "from array import array\n",
        "\n",
        "mylist = []\n",
        "\n",
        "for i in range(0,len(Y_test)):\n",
        "    x = random.randrange(0, 4)\n",
        "    mylist.append(x)\n",
        "    \n",
        "Y_dummy1=numpy.array(mylist)"
      ],
      "id": "af080f5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "c=collections.Counter(Y_dummy1)\n",
        "df = pd.DataFrame.from_records(list(dict(c).items()), columns=['class','count']).sort_values('class')\n",
        "df"
      ],
      "id": "af6b900a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(classification_report(le.inverse_transform(Y_test), le.inverse_transform(Y_dummy1)))"
      ],
      "id": "1b1fc2d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### dummy 2 : there are 3 class, random assign to each share:\n",
        "\n",
        "each class in Y_test \n"
      ],
      "id": "e74b058b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "c=collections.Counter(Y_test)\n",
        "df = pd.DataFrame.from_records(list(dict(c).items()), columns=['class','count']).sort_values('class')\n",
        "df"
      ],
      "id": "10bc108b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "Y_dummy2=numpy.array(random.choices([0, 1, 2,3], [218/sum(Y_test), 208/sum(Y_test), 218/sum(Y_test),264/sum(Y_test)], k=len(Y_test)))"
      ],
      "id": "6bbd3699",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "c=collections.Counter(Y_dummy2)\n",
        "df = pd.DataFrame.from_records(list(dict(c).items()), columns=['class','count']).sort_values('class')\n",
        "df"
      ],
      "id": "e4a27be1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(classification_report(le.inverse_transform(Y_test), le.inverse_transform(Y_dummy2)))"
      ],
      "id": "8458328f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### model Preformance"
      ],
      "id": "241799d9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grid_dict = {0: 'XGB', 1: 'random forest', 2: 'XGB non tune',3: 'ramdon forest non tune',4:'Logistic regression non tune' }\n",
        "\n",
        "for i, model in enumerate(Grids):\n",
        "    print('{} Test Accuracy: {}'.format(grid_dict[i],\n",
        "    model.score(X_test,Y_test)))\n",
        "    #print('{} Best Params: {}'.format(grid_dict[i], model.best_params_))"
      ],
      "id": "27a5806c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_ml=Grid_xgb.best_estimator_"
      ],
      "id": "88a52fe9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "type(best_ml)"
      ],
      "id": "faa38e09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### model feature importances"
      ],
      "id": "baa52383"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "vi=best_ml.steps[1][1].feature_importances_\n",
        "vi"
      ],
      "id": "e28bd58c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## get pipeline feature names\n",
        "var_name=best_ml[:-1].get_feature_names_out()"
      ],
      "id": "fd775e3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dataset = pd.DataFrame({'feature': var_name, 'importances': vi}, columns=['feature', 'importances']).sort_values('importances',ascending=False)\n",
        "dataset"
      ],
      "id": "90722fbb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Using predict method to test the model\n",
        "Y_pred_dt = best_ml.predict(X_test) #always gets x and retuns y\n",
        "#Y_pred_dt"
      ],
      "id": "6c8c2b7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, Y_pred_dt))"
      ],
      "id": "8ab977ff",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "reverse target label back to A B C D"
      ],
      "id": "0c26d9f4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(le.inverse_transform(Y_test), le.inverse_transform(Y_pred_dt)))"
      ],
      "id": "dbfbec40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## save model\n"
      ],
      "id": "b7ca70b6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from joblib import dump, load\n",
        "dump(Grid_xgb, 'trained_grid_multi_calss.joblib', compress=True)  "
      ],
      "id": "65024553",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## load model\n"
      ],
      "id": "046cec64"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "model_reload = load('trained_grid_multi_calss.joblib') "
      ],
      "id": "fc6eaeb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "best_ml=model_reload.best_estimator_"
      ],
      "id": "bb0bc93f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## final prediction\n"
      ],
      "id": "cbcb640d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Y_pred_dt_final =best_ml.predict(X_val) #always gets x and retuns y\n",
        "\n",
        "\n",
        "Y_pred_dt_final_lable=le.inverse_transform(Y_pred_dt_final)\n",
        "Y_pred_dt_final_lable[0:5]"
      ],
      "id": "e5b6ceda",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import collections, numpy\n",
        "c=collections.Counter(Y_pred_dt_final_lable)\n",
        "df = pd.DataFrame.from_records(list(dict(c).items()), columns=['class','count']).sort_values('class')\n",
        "df"
      ],
      "id": "7217bb99",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# reference:\n",
        "\n",
        "https://www.kaggle.com/code/mittalvasu95/multi-class-classification-c101\n"
      ],
      "id": "74aea9c3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}